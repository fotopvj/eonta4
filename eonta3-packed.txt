================================================================
RepopackPy Output File
================================================================

This file was generated by RepopackPy on: 2025-03-16T20:06:17.933945

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and RepopackPy's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

For more information about RepopackPy, visit: https://github.com/abinthomasonline/repopack-py

================================================================
Repository Structure
================================================================
client/
  assets/
    css/
      main.css
    img/
      logo.svg
  src/
    components/
      BoundaryTransitionSettings.jsx
      EontaCompositionViewer.jsx
      PathRecoderUI.jsx
    services/
      AudioUtils.js
      BoundaryTransitionManager.js
      EnhancedAudioServices.js
      MapUtils.js
      PathRecorderService.js
    app.js
  index.html
docs/
  eonta-structure-summary.md
  eonta3 structure map.png
  ffmpeg-install-updated.md
  installation-guide.md
  render-deployment-guide.md
routes/
  audio.js
  compositions.js
  users.js
server/
  config/
    audio.js
  models/
    PathRecording.js
  services/
    AudioConverter.js
    EnhancedEmailService.js
    PathMapGenerator.js
  app.js
README.md
build.sh
package.json
render.yaml

================================================================
Repository Files
================================================================

================
File: render.yaml
================
services:
  - type: web
    name: eonta
    env: node
    buildCommand: npm install && apt-get update && apt-get install -y ffmpeg
    startCommand: npm start
    envVars:
      - key: NODE_ENV
        value: production
      - key: PORT
        value: 3000
      - key: MONGODB_URI
        sync: false
      - key: AWS_ACCESS_KEY_ID
        sync: false
      - key: AWS_SECRET_ACCESS_KEY
        sync: false
      - key: AWS_REGION
        value: us-east-1
      - key: S3_BUCKET_NAME
        sync: false
      - key: JWT_SECRET
        generateValue: true
      - key: JWT_EXPIRATION
        value: 7d
      - key: CORS_ALLOWED_ORIGINS
        value: https://eonta.onrender.com
      - key: SESSION_SECRET
        generateValue: true
      - key: MAX_AUDIO_FILE_SIZE_MB
        value: 30
      - key: ALLOWED_AUDIO_FORMATS
        value: wav,mp3,m4a,ogg,aac,flac

================
File: README.md
================
# eonta3
modernized and more secure version of eonta

================
File: build.sh
================
#!/bin/bash

# Install dependencies
npm install

# Install FFmpeg
apt-get update
apt-get install -y ffmpeg

# Verify FFmpeg installation
ffmpeg -version

# Build your application (if needed)
# npm run build

================
File: package.json
================
{
  "name": "eonta3",
  "version": "1.0.0",
  "description": "Modernized and more secure version of EONTA - Explore audio through geographic location",
  "main": "server/app.js",
  "scripts": {
    "start": "node server/app.js",
    "dev": "nodemon server/app.js",
    "test": "jest"
  },
  "engines": {
    "node": ">=14.0.0"
  },
  "dependencies": {
    "aws-sdk": "^2.1400.0",
    "bcryptjs": "^2.4.3",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "express": "^4.18.2",
    "fluent-ffmpeg": "^2.1.3",
    "jsonwebtoken": "^9.0.0",
    "mongoose": "^7.3.1",
    "multer": "^1.4.5-lts.1",
    "nodemailer": "^6.9.3",
    "tmp": "^0.2.3"
  },
  "devDependencies": {
    "jest": "^29.5.0",
    "nodemon": "^3.1.9"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/fotopvj/eonta3.git"
  },
  "keywords": [
    "audio",
    "geolocation",
    "mapping",
    "composition",
    "gps",
    "immersive audio"
  ],
  "author": "",
  "license": "MIT"
}

================
File: server/app.js
================
// Load environment variables
require('dotenv').config();

const express = require('express');
const mongoose = require('mongoose');
const cors = require('cors');
const path = require('path');

// Import routes
const userRoutes = require('../routes/users');
const compositionRoutes = require('../routes/compositions');
const audioRoutes = require('../routes/audio');

// Create Express app
const app = express();

// Set port
const PORT = process.env.PORT || 3000;

// Middleware
app.use(cors({
  origin: process.env.CORS_ALLOWED_ORIGINS ? 
    process.env.CORS_ALLOWED_ORIGINS.split(',') : 
    ['http://localhost:3000', 'https://eonta.app']
}));
app.use(express.json());
app.use(express.urlencoded({ extended: true }));

// Connect to MongoDB
mongoose.connect(process.env.MONGODB_URI, {
  useNewUrlParser: true,
  useUnifiedTopology: true
})
.then(() => console.log('MongoDB connected successfully'))
.catch(err => console.error('MongoDB connection error:', err));

// Root route - Welcome page
app.get('/', (req, res) => {
  res.status(200).json({
    message: 'Welcome to EONTA API',
    version: '1.0.0',
    description: 'API for the EONTA audio-geographic composition platform',
    endpoints: {
      audio: '/api/audio',
      users: '/api/users',
      compositions: '/api/compositions',
      health: '/api/health'
    },
    documentation: '/api/docs',
    status: 'running'
  });
});

// Static files - serve the client build directory in production
if (process.env.NODE_ENV === 'production') {
  app.use(express.static(path.join(__dirname, '../client/build')));
}

// API Routes
app.use('/api/users', userRoutes);
app.use('/api/compositions', compositionRoutes);
app.use('/api/audio', audioRoutes);

// API Documentation route
app.get('/api/docs', (req, res) => {
  res.status(200).json({
    title: 'EONTA API Documentation',
    description: 'API endpoints for the EONTA platform',
    version: '1.0.0',
    endpoints: {
      users: {
        register: {
          method: 'POST',
          path: '/api/users/register',
          description: 'Register a new user',
          body: {
            name: 'string',
            email: 'string',
            password: 'string'
          }
        },
        login: {
          method: 'POST',
          path: '/api/users/login',
          description: 'Login a user',
          body: {
            email: 'string',
            password: 'string'
          }
        },
        profile: {
          method: 'GET',
          path: '/api/users/profile',
          description: 'Get user profile information',
          auth: 'Required'
        }
      },
      compositions: {
        getAllCompositions: {
          method: 'GET',
          path: '/api/compositions',
          description: 'Get all compositions or filter by parameters'
        },
        createComposition: {
          method: 'POST',
          path: '/api/compositions',
          description: 'Create a new composition',
          auth: 'Required'
        },
        getCompositionById: {
          method: 'GET',
          path: '/api/compositions/:id',
          description: 'Get a specific composition by ID'
        },
        updateComposition: {
          method: 'PUT',
          path: '/api/compositions/:id',
          description: 'Update a composition',
          auth: 'Required'
        },
        deleteComposition: {
          method: 'DELETE',
          path: '/api/compositions/:id',
          description: 'Delete a composition',
          auth: 'Required'
        },
        shareComposition: {
          method: 'POST',
          path: '/api/compositions/:id/share',
          description: 'Share a composition via email',
          auth: 'Required'
        }
      },
      audio: {
        uploadAudio: {
          method: 'POST',
          path: '/api/audio/upload',
          description: 'Upload an audio file (auto-converts to optimal format)',
          auth: 'Required',
          contentType: 'multipart/form-data',
          formData: {
            audio: 'file'
          }
        },
        getAudioUrl: {
          method: 'GET',
          path: '/api/audio/:fileName',
          description: 'Get a signed URL to access an audio file',
          auth: 'Required'
        }
      }
    }
  });
});

// Basic route for API health check
app.get('/api/health', (req, res) => {
  res.status(200).json({ 
    status: 'ok',
    message: 'EONTA API is running',
    timestamp: new Date(),
    environment: process.env.NODE_ENV || 'development'
  });
});

// Serve React app for any other routes in production
if (process.env.NODE_ENV === 'production') {
  app.get('*', (req, res) => {
    res.sendFile(path.join(__dirname, '../client/build/index.html'));
  });
}

// Error handling middleware
app.use((err, req, res, next) => {
  console.error(err.stack);
  res.status(500).json({ 
    success: false, 
    message: 'Server error',
    error: process.env.NODE_ENV === 'development' ? err.message : undefined
  });
});

// Start server
app.listen(PORT, () => {
  console.log(`Server running on port ${PORT}`);
  console.log(`Environment: ${process.env.NODE_ENV || 'development'}`);
});

module.exports = app;

================
File: server/config/audio.js
================
/**
 * Audio configuration settings for EONTA
 */
module.exports = {
  /**
   * Target audio format for web streaming
   */
  targetFormat: {
    codec: 'libmp3lame',          // MP3 codec
    bitrate: 192,                 // 192kbps - good quality for most music
    channels: 2,                  // Stereo
    sampleRate: 44100,            // 44.1 kHz
    extension: '.mp3',
    mimeType: 'audio/mpeg'
  },

  /**
   * List of mime types that need conversion
   * MP3 files don't need conversion, everything else does
   */
  conversionNeeded: [
    'audio/wav',
    'audio/x-wav',
    'audio/flac',
    'audio/x-flac',
    'audio/ogg',
    'audio/vorbis',
    'audio/aac',
    'audio/m4a',
    'audio/x-m4a',
    'audio/x-aiff',
    'audio/aiff'
  ],

  /**
   * Common MIME types for audio files
   */
  mimeTypes: {
    '.mp3': 'audio/mpeg',
    '.wav': 'audio/wav',
    '.ogg': 'audio/ogg',
    '.flac': 'audio/flac',
    '.aac': 'audio/aac',
    '.m4a': 'audio/x-m4a',
    '.aiff': 'audio/aiff'
  },

  /**
   * Maximum file size in MB
   * This is overridden by the MAX_AUDIO_FILE_SIZE_MB environment variable if set
   */
  maxFileSizeMB: 30,

  /**
   * Default caching settings for audio files
   */
  caching: {
    maxAge: 31536000 // 1 year in seconds
  }
};

================
File: server/models/PathRecording.js
================
const mongoose = require('mongoose');
const Schema = mongoose.Schema;

/**
 * Path Recording Schema
 * Stores GPS path recordings and associated audio data
 */
const PathRecordingSchema = new Schema({
  user: {
    type: Schema.Types.ObjectId,
    ref: 'User',
    required: true,
    index: true // Index for better query performance
  },
  composition: {
    type: Schema.Types.ObjectId,
    ref: 'Composition',
    required: true,
    index: true
  },
  recordingId: {
    type: String,
    required: true,
    unique: true,
    trim: true, // Remove whitespace
    validate: {
      validator: function(v) {
        return /^[a-zA-Z0-9_-]+$/.test(v); // Allow only alphanumeric, underscore, and dash
      },
      message: props => `${props.value} is not a valid recording ID!`
    }
  },
  path: [{
    lat: {
      type: Number,
      required: true,
      min: -90,
      max: 90
    },
    lng: {
      type: Number,
      required: true,
      min: -180,
      max: 180
    },
    timestamp: {
      type: Date,
      default: Date.now
    },
    timeSinceStart: {
      type: Number,
      required: true,
      min: 0
    },
    accuracy: {
      type: Number,
      min: 0
    },
    alt: {
      type: Number
    }
  }],
  audioEvents: [{
    timestamp: {
      type: Date,
      required: true
    },
    timeSinceStart: {
      type: Number,
      required: true,
      min: 0
    },
    activeRegions: [{
      regionId: {
        type: Schema.Types.ObjectId,
        ref: 'AudioRegion'
      },
      volume: {
        type: Number,
        default: 1.0,
        min: 0,
        max: 1.0
      },
      effects: {
        type: Object,
        default: {}
      }
    }]
  }],
  duration: {
    type: Number,
    required: true,
    min: 0
  },
  startTime: {
    type: Date,
    required: true
  },
  endTime: {
    type: Date,
    required: true,
    validate: {
      validator: function(v) {
        return v >= this.startTime; // End time must be after start time
      },
      message: props => 'End time must be after start time!'
    }
  },
  status: {
    type: String,
    enum: ['processing', 'completed', 'error'],
    default: 'processing'
  },
  downloadUrl: {
    type: String,
    trim: true,
    validate: {
      validator: function(v) {
        // Only validate if present
        if (!v) return true;
        
        // Simple URL validation
        try {
          new URL(v);
          return true;
        } catch (e) {
          return false;
        }
      },
      message: props => `${props.value} is not a valid URL!`
    }
  },
  mapImageUrl: {
    type: String,
    trim: true,
    validate: {
      validator: function(v) {
        // Only validate if present
        if (!v) return true;
        
        // Simple URL validation
        try {
          new URL(v);
          return true;
        } catch (e) {
          return false;
        }
      },
      message: props => `${props.value} is not a valid URL!`
    }
  },
  expiresAt: {
    type: Date,
    validate: {
      validator: function(v) {
        // Only validate if present
        if (!v) return true;
        
        return v > new Date(); // Expiration date must be in the future
      },
      message: props => 'Expiration date must be in the future!'
    }
  },
  error: {
    type: String
  },
  createdAt: {
    type: Date,
    default: Date.now,
    index: true // Index for sorting and filtering
  },
  stats: {
    totalDistance: {
      type: Number, // meters
      default: 0,
      min: 0
    },
    averageSpeed: {
      type: Number, // meters per second
      default: 0,
      min: 0
    },
    uniqueRegionsVisited: {
      type: Number,
      default: 0,
      min: 0
    },
    downloadCount: {
      type: Number,
      default: 0,
      min: 0
    }
  },
  metadata: {
    device: {
      type: String,
      trim: true,
      maxlength: 200 // Avoid excessively long strings
    },
    browser: {
      type: String,
      trim: true,
      maxlength: 200
    },
    userAgent: {
      type: String,
      trim: true,
      maxlength: 500
    },
    ipAddress: {
      type: String,
      trim: true,
      // Store hashed IP for privacy
      set: function(v) {
        // Only hash if value is present
        if (!v) return v;
        
        // Use built-in crypto module to hash IP
        const crypto = require('crypto');
        return crypto.createHash('sha256').update(v).digest('hex');
      }
    }
  }
}, {
  // Add timestamps for better auditing
  timestamps: true,
  
  // Add toJSON option to clean up output
  toJSON: {
    virtuals: true,
    transform: function(doc, ret) {
      delete ret.__v; // Remove version key
      delete ret.metadata.ipAddress; // Don't expose IP, even in hashed form
      return ret;
    }
  }
});

// Index for quick lookups - combined indices for common queries
PathRecordingSchema.index({ user: 1, createdAt: -1 });
PathRecordingSchema.index({ recordingId: 1 }, { unique: true });
PathRecordingSchema.index({ composition: 1 });
PathRecordingSchema.index({ status: 1, createdAt: -1 }); // For finding processing or error records

// Define virtual for whether the download is still valid
PathRecordingSchema.virtual('isDownloadValid').get(function() {
  if (!this.expiresAt) return false;
  return new Date() < this.expiresAt;
});

// Instance method to calculate total distance
PathRecordingSchema.methods.calculateTotalDistance = function() {
  if (!this.path || this.path.length < 2) return 0;
  
  let totalDistance = 0;
  
  for (let i = 1; i < this.path.length; i++) {
    const point1 = this.path[i - 1];
    const point2 = this.path[i];
    totalDistance += calculateDistance(
      point1.lat, point1.lng,
      point2.lat, point2.lng
    );
  }
  
  return totalDistance;
};

// Instance method to validate path
PathRecordingSchema.methods.validatePath = function() {
  if (!this.path || this.path.length < 2) {
    return { valid: false, message: 'Path must contain at least 2 points' };
  }
  
  // Check for invalid coordinates
  for (const point of this.path) {
    if (point.lat < -90 || point.lat > 90 || point.lng < -180 || point.lng > 180) {
      return { 
        valid: false, 
        message: `Invalid coordinates: lat=${point.lat}, lng=${point.lng}` 
      };
    }
  }
  
  return { valid: true };
};

// Utility function to calculate distance between two points using Haversine formula
function calculateDistance(lat1, lon1, lat2, lon2) {
  const R = 6371e3; // Earth radius in meters
  const φ1 = lat1 * Math.PI / 180;
  const φ2 = lat2 * Math.PI / 180;
  const Δφ = (lat2 - lat1) * Math.PI / 180;
  const Δλ = (lon2 - lon1) * Math.PI / 180;

  const a = Math.sin(Δφ / 2) * Math.sin(Δφ / 2) +
          Math.cos(φ1) * Math.cos(φ2) *
          Math.sin(Δλ / 2) * Math.sin(Δλ / 2);
  const c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a));

  return R * c; // Distance in meters
}

// Pre-save hook to calculate statistics and validate data
PathRecordingSchema.pre('save', async function(next) {
  try {
    if (this.isNew || this.isModified('path')) {
      // Validate path
      const pathValidation = this.validatePath();
      if (!pathValidation.valid) {
        return next(new Error(pathValidation.message));
      }
      
      // Calculate total distance
      this.stats.totalDistance = this.calculateTotalDistance();
      
      // Calculate average speed (if duration > 0)
      if (this.duration > 0) {
        this.stats.averageSpeed = this.stats.totalDistance / (this.duration / 1000);
      }
      
      // Count unique regions visited (using set of region IDs)
      const uniqueRegions = new Set();
      this.audioEvents.forEach(event => {
        event.activeRegions.forEach(region => {
          if (region.regionId) {
            uniqueRegions.add(region.regionId.toString());
          }
        });
      });
      
      this.stats.uniqueRegionsVisited = uniqueRegions.size;
    }
    
    next();
  } catch (error) {
    next(error);
  }
});

// Static method to find recent recordings by user
PathRecordingSchema.statics.findRecentByUser = function(userId, limit = 10) {
  return this.find({ user: userId })
    .sort({ createdAt: -1 })
    .limit(limit)
    .select('-path -audioEvents') // Exclude large arrays for better performance
    .exec();
};

// Static method to find completed recordings for a composition
PathRecordingSchema.statics.findCompletedForComposition = function(compositionId, limit = 20) {
  return this.find({ 
    composition: compositionId,
    status: 'completed'
  })
  .sort({ createdAt: -1 })
  .limit(limit)
  .select('-path -audioEvents')
  .exec();
};

const PathRecording = mongoose.model('PathRecording', PathRecordingSchema);

module.exports = PathRecording;

================
File: server/services/PathMapGenerator.js
================
const axios = require('axios');
const fs = require('fs');
const path = require('path');
const { createCanvas } = require('canvas');
const AWS = require('aws-sdk');
const crypto = require('crypto');
const { promisify } = require('util');

// Use promisify for fs operations
const writeFileAsync = promisify(fs.writeFile);
const unlinkAsync = promisify(fs.unlink);
const mkdirAsync = promisify(fs.mkdir);

/**
 * Path Map Generator Service
 * Generates visual maps of user paths through audio installations
 */
class PathMapGenerator {
  constructor() {
    // Initialize AWS only if credentials are available
    if (
      process.env.AWS_ACCESS_KEY_ID &&
      process.env.AWS_SECRET_ACCESS_KEY &&
      process.env.AWS_REGION
    ) {
      this.s3 = new AWS.S3({
        accessKeyId: process.env.AWS_ACCESS_KEY_ID,
        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
        region: process.env.AWS_REGION
      });
    } else {
      console.warn('AWS credentials not configured. S3 uploads will not work.');
    }
  }

  /**
   * Generate a static map image using the Google Maps Static API
   * @param {Object} recording - The path recording object
   * @param {Object} composition - The composition object
   * @returns {Promise<string>} - The URL of the generated map image
   */
  async generatePathMapImage(recording, composition) {
    try {
      // Validate input
      if (!recording || !recording.path || !recording.path.length) {
        throw new Error('Invalid recording data: missing path');
      }

      if (!recording.recordingId) {
        throw new Error('Invalid recording data: missing recordingId');
      }

      // Extract path coordinates from the recording
      const pathCoordinates = recording.path.map(point => {
        // Validate coordinates
        if (typeof point.lat !== 'number' || typeof point.lng !== 'number' ||
            point.lat < -90 || point.lat > 90 || point.lng < -180 || point.lng > 180) {
          throw new Error(`Invalid coordinates: ${JSON.stringify(point)}`);
        }
        return `${point.lat},${point.lng}`;
      });
      
      // If there are too many points for a URL, reduce the number of points
      // Google Maps Static API has URL length limitations
      const simplifiedPath = this.simplifyPath(pathCoordinates, 100); // Max 100 points
      
      try {
        // Try to use Google Maps Static API if API key is available
        if (process.env.GOOGLE_MAPS_API_KEY) {
          return await this.generateGoogleMapsImage(
            simplifiedPath, 
            recording, 
            composition
          );
        } else {
          console.warn('Google Maps API key not configured. Using fallback image generator.');
          return await this.generateFallbackPathImage(recording);
        }
      } catch (error) {
        console.error('Error with Google Maps image generation:', error);
        return await this.generateFallbackPathImage(recording);
      }
    } catch (error) {
      console.error('Error generating path map image:', error);
      return null;
    }
  }

  /**
   * Generate map image using Google Maps Static API
   * @param {Array} simplifiedPath - Simplified array of coordinate strings
   * @param {Object} recording - The path recording object
   * @param {Object} composition - The composition object
   * @returns {Promise<string>} - The URL of the generated map image
   */
  async generateGoogleMapsImage(simplifiedPath, recording, composition) {
    // Create Google Maps Static API URL
    const apiKey = process.env.GOOGLE_MAPS_API_KEY;
    
    // Use composition center if available, otherwise use first point from path
    let mapCenter;
    if (composition && composition.location && composition.location.coordinates) {
      mapCenter = composition.location.coordinates.join(',');
    } else {
      const firstPoint = recording.path[0];
      mapCenter = `${firstPoint.lat},${firstPoint.lng}`;
    }
    
    const mapZoom = 15; // Adjust based on path size
    const mapSize = '600x400';
    const mapType = 'roadmap';
    
    // Create path parameter with color and weight
    const pathParam = `path=color:0x0000FFAA|weight:4|${simplifiedPath.join('|')}`;
    
    // Add markers for start (green) and end (red) points
    const firstCoord = recording.path[0];
    const lastCoord = recording.path[recording.path.length - 1];
    const startMarker = `markers=color:green|${firstCoord.lat},${firstCoord.lng}`;
    const endMarker = `markers=color:red|${lastCoord.lat},${lastCoord.lng}`;
    
    // Construct the final URL
    const staticMapUrl = `https://maps.googleapis.com/maps/api/staticmap?center=${mapCenter}&zoom=${mapZoom}&size=${mapSize}&maptype=${mapType}&${pathParam}&${startMarker}&${endMarker}&key=${apiKey}`;
    
    // For higher security, we'll download the image and upload to our own S3 rather than sending Google Maps URL directly
    // Set a timeout for the request
    const axiosOptions = {
      responseType: 'arraybuffer',
      timeout: 15000 // 15 seconds timeout
    };
    
    const imageResponse = await axios.get(staticMapUrl, axiosOptions);
    
    // Generate a secure temporary file path
    const tempDir = path.join(__dirname, '../temp');
    await this.ensureDirExists(tempDir);
    
    const randomSuffix = crypto.randomBytes(8).toString('hex');
    const tempFilePath = path.join(tempDir, `path_${recording.recordingId}_${randomSuffix}.png`);
    
    // Save to temp file
    await writeFileAsync(tempFilePath, imageResponse.data);
    
    try {
      // Upload to S3
      const s3Key = `path-maps/${recording.recordingId}.png`;
      const imageUrl = await this.uploadToS3(tempFilePath, s3Key);
      
      // Remove temp file
      await unlinkAsync(tempFilePath);
      
      return imageUrl;
    } catch (error) {
      console.error('Error uploading to S3:', error);
      // Remove temp file even if upload fails
      try {
        await unlinkAsync(tempFilePath);
      } catch (unlinkError) {
        console.error('Error removing temp file:', unlinkError);
      }
      throw error;
    }
  }
  
  /**
   * Ensure directory exists
   * @param {string} dirPath - Directory path
   */
  async ensureDirExists(dirPath) {
    try {
      await mkdirAsync(dirPath, { recursive: true });
    } catch (error) {
      // Ignore if directory already exists
      if (error.code !== 'EEXIST') {
        throw error;
      }
    }
  }
  
  /**
   * Upload file to S3
   * @param {string} filePath - Path to the file
   * @param {string} s3Key - S3 key for the file
   * @returns {Promise<string>} - Presigned URL
   */
  async uploadToS3(filePath, s3Key) {
    if (!this.s3) {
      throw new Error('S3 not configured');
    }
    
    try {
      await this.s3.upload({
        Bucket: process.env.S3_BUCKET_NAME,
        Key: s3Key,
        Body: fs.createReadStream(filePath),
        ContentType: 'image/png',
        ACL: 'private'
      }).promise();
      
      // Generate pre-signed URL (valid for 7 days, same as audio)
      const imageUrl = this.s3.getSignedUrl('getObject', {
        Bucket: process.env.S3_BUCKET_NAME,
        Key: s3Key,
        Expires: 7 * 24 * 60 * 60 // 7 days in seconds
      });
      
      return imageUrl;
    } catch (error) {
      console.error('S3 upload error:', error);
      throw new Error('Failed to upload image to S3');
    }
  }

  /**
   * Simplifies a path to have fewer points while maintaining the general shape
   * @param {Array} path - Array of coordinate strings
   * @param {Number} maxPoints - Maximum number of points to keep
   * @returns {Array} - Simplified path
   */
  simplifyPath(path, maxPoints) {
    if (!path || path.length <= maxPoints) {
      return path || [];
    }
    
    // Simple algorithm to reduce points - keep first, last, and evenly spaced points
    const result = [path[0]];
    const step = Math.floor(path.length / (maxPoints - 2));
    
    for (let i = step; i < path.length - step; i += step) {
      result.push(path[i]);
    }
    
    result.push(path[path.length - 1]);
    return result;
  }
  
  /**
   * Generates a fallback path image using HTML Canvas
   * @param {Object} recording - The path recording object
   * @returns {Promise<string>} - The URL of the generated image
   */
  async generateFallbackPathImage(recording) {
    try {
      // Validate input
      if (!recording || !recording.path || recording.path.length < 2) {
        throw new Error('Invalid recording data for fallback image');
      }
      
      // Extract path coordinates
      const pathPoints = recording.path.map(point => ({
        x: point.lng,
        y: point.lat
      }));
      
      // Find min/max coordinates to determine bounds
      const bounds = pathPoints.reduce((acc, point) => {
        return {
          minX: Math.min(acc.minX, point.x),
          maxX: Math.max(acc.maxX, point.x),
          minY: Math.min(acc.minY, point.y),
          maxY: Math.max(acc.maxY, point.y)
        };
      }, {
        minX: Infinity,
        maxX: -Infinity,
        minY: Infinity,
        maxY: -Infinity
      });
      
      // Add padding
      const padding = 0.0002; // Approximately 20 meters in lat/lng
      bounds.minX -= padding;
      bounds.maxX += padding;
      bounds.minY -= padding;
      bounds.maxY += padding;
      
      // Create canvas
      const width = 600;
      const height = 400;
      const canvas = createCanvas(width, height);
      const ctx = canvas.getContext('2d');
      
      // Fill background
      ctx.fillStyle = '#F0F0F0';
      ctx.fillRect(0, 0, width, height);
      
      // Function to convert geo coordinates to canvas coordinates
      const mapToCanvas = (x, y) => {
        const canvasX = ((x - bounds.minX) / (bounds.maxX - bounds.minX)) * width;
        const canvasY = height - ((y - bounds.minY) / (bounds.maxY - bounds.minY)) * height;
        return { x: canvasX, y: canvasY };
      };
      
      // Draw path
      ctx.beginPath();
      const firstPoint = mapToCanvas(pathPoints[0].x, pathPoints[0].y);
      ctx.moveTo(firstPoint.x, firstPoint.y);
      
      for (let i = 1; i < pathPoints.length; i++) {
        const point = mapToCanvas(pathPoints[i].x, pathPoints[i].y);
        ctx.lineTo(point.x, point.y);
      }
      
      ctx.strokeStyle = 'rgba(0, 0, 255, 0.7)';
      ctx.lineWidth = 3;
      ctx.stroke();
      
      // Draw start point (green)
      const startPoint = mapToCanvas(pathPoints[0].x, pathPoints[0].y);
      ctx.beginPath();
      ctx.arc(startPoint.x, startPoint.y, 8, 0, Math.PI * 2);
      ctx.fillStyle = 'green';
      ctx.fill();
      
      // Draw end point (red)
      const endPoint = mapToCanvas(pathPoints[pathPoints.length - 1].x, pathPoints[pathPoints.length - 1].y);
      ctx.beginPath();
      ctx.arc(endPoint.x, endPoint.y, 8, 0, Math.PI * 2);
      ctx.fillStyle = 'red';
      ctx.fill();
      
      // Add title and legend
      ctx.font = 'bold 16px Arial';
      ctx.fillStyle = '#333';
      ctx.fillText('Your Path Through the Sound Installation', 20, 30);
      
      ctx.font = '12px Arial';
      ctx.fillStyle = '#333';
      ctx.fillText('Start Point', 30, height - 40);
      ctx.beginPath();
      ctx.arc(20, height - 36, 6, 0, Math.PI * 2);
      ctx.fillStyle = 'green';
      ctx.fill();
      
      ctx.fillStyle = '#333';
      ctx.fillText('End Point', 100, height - 40);
      ctx.beginPath();
      ctx.arc(90, height - 36, 6, 0, Math.PI * 2);
      ctx.fillStyle = 'red';
      ctx.fill();
      
      // Add timestamp
      ctx.fillStyle = '#666';
      ctx.font = '10px Arial';
      ctx.fillText(`Generated: ${new Date().toLocaleString()}`, 20, height - 15);
      
      // Ensure temp directory exists
      const tempDir = path.join(__dirname, '../temp');
      await this.ensureDirExists(tempDir);
      
      // Generate a secure temporary file path
      const randomSuffix = crypto.randomBytes(8).toString('hex');
      const tempFilePath = path.join(tempDir, `path_${recording.recordingId}_${randomSuffix}.png`);
      
      // Save to temp file
      const buffer = canvas.toBuffer('image/png');
      await writeFileAsync(tempFilePath, buffer);
      
      try {
        // Upload to S3
        const s3Key = `path-maps/${recording.recordingId}.png`;
        const imageUrl = await this.uploadToS3(tempFilePath, s3Key);
        
        // Remove temp file
        await unlinkAsync(tempFilePath);
        
        return imageUrl;
      } catch (error) {
        console.error('Error uploading fallback image to S3:', error);
        // Remove temp file even if upload fails
        try {
          await unlinkAsync(tempFilePath);
        } catch (unlinkError) {
          console.error('Error removing temp file:', unlinkError);
        }
        return null;
      }
    } catch (error) {
      console.error('Error generating fallback path image:', error);
      return null;
    }
  }
}

module.exports = new PathMapGenerator();

================
File: server/services/EnhancedEmailService.js
================
const nodemailer = require('nodemailer');
const pathMapGenerator = require('./PathMapGenerator');
const { sanitizeHtml } = require('../utils/security'); // Add this utility
const rateLimit = require('express-rate-limit'); // Add this dependency

/**
 * Enhanced Email Service
 * Sends emails with audio compositions and path maps
 */
class EnhancedEmailService {
  constructor() {
    // Configure nodemailer with secure settings
    this.transporter = null;
    this.setupTransporter();
    
    // Track email sending for rate limiting
    this.emailSendAttempts = new Map();
    this.maxEmailsPerHour = 10; // Limit emails per user/IP
  }
  
  /**
   * Set up email transporter with environment variables
   */
  setupTransporter() {
    try {
      // Validate required environment variables
      const requiredEnvVars = [
        'EMAIL_HOST', 
        'EMAIL_PORT', 
        'EMAIL_USER', 
        'EMAIL_PASSWORD',
        'EMAIL_FROM'
      ];
      
      for (const envVar of requiredEnvVars) {
        if (!process.env[envVar]) {
          throw new Error(`Missing required environment variable: ${envVar}`);
        }
      }
      
      // Parse secure flag properly
      const secureConnection = process.env.EMAIL_SECURE === 'true';
      
      // Create transporter with secure settings
      this.transporter = nodemailer.createTransport({
        host: process.env.EMAIL_HOST,
        port: parseInt(process.env.EMAIL_PORT, 10),
        secure: secureConnection,
        auth: {
          user: process.env.EMAIL_USER,
          pass: process.env.EMAIL_PASSWORD
        },
        tls: {
          // Require TLS
          rejectUnauthorized: true,
          minVersion: 'TLSv1.2'
        }
      });
      
      // Verify connection configuration
      this.transporter.verify((error) => {
        if (error) {
          console.error('Email service configuration error:', error);
        } else {
          console.log('Email service ready to send messages');
        }
      });
    } catch (error) {
      console.error('Failed to set up email transporter:', error);
      // The service will attempt to reconnect when sending emails
    }
  }
  
  /**
   * Check if email rate limit is exceeded
   * @param {String} identifier - User email or IP address
   * @returns {Boolean} - Whether rate limit is exceeded
   */
  isRateLimited(identifier) {
    const now = Date.now();
    const hourAgo = now - (60 * 60 * 1000);
    
    // Get attempts in the last hour
    if (!this.emailSendAttempts.has(identifier)) {
      this.emailSendAttempts.set(identifier, []);
    }
    
    // Get attempts and filter to last hour only
    let attempts = this.emailSendAttempts.get(identifier);
    attempts = attempts.filter(timestamp => timestamp > hourAgo);
    
    // Update the stored attempts
    this.emailSendAttempts.set(identifier, attempts);
    
    // Check if rate limit exceeded
    return attempts.length >= this.maxEmailsPerHour;
  }
  
  /**
   * Record an email send attempt
   * @param {String} identifier - User email or IP address
   */
  recordEmailAttempt(identifier) {
    if (!this.emailSendAttempts.has(identifier)) {
      this.emailSendAttempts.set(identifier, []);
    }
    
    const attempts = this.emailSendAttempts.get(identifier);
    attempts.push(Date.now());
    
    this.emailSendAttempts.set(identifier, attempts);
  }
  
  /**
   * Validate email format
   * @param {String} email - Email to validate
   * @returns {Boolean} Whether email is valid
   */
  isValidEmail(email) {
    if (!email || typeof email !== 'string') return false;
    
    // Basic email format validation using regex
    const emailRegex = /^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$/;
    return emailRegex.test(email);
  }
  
  /**
   * Sends an enhanced email with both the audio download link and path map
   * @param {String} email - Recipient email address
   * @param {String} downloadUrl - URL for the audio composition download
   * @param {Date} expiresAt - Expiration date for the download link
   * @param {String} compositionTitle - Title of the original composition
   * @param {Object} recording - The path recording object
   * @param {Object} composition - The original composition object
   * @param {String} requestIp - IP address of the requester (for rate limiting)
   * @returns {Promise} - Result of sending the email
   */
  async sendEnhancedDownloadEmail(email, downloadUrl, expiresAt, compositionTitle, recording, composition, requestIp) {
    // Validate inputs
    if (!this.isValidEmail(email)) {
      throw new Error('Invalid email address');
    }
    
    if (!downloadUrl || typeof downloadUrl !== 'string') {
      throw new Error('Invalid download URL');
    }
    
    if (!(expiresAt instanceof Date)) {
      throw new Error('Invalid expiration date');
    }
    
    // Apply rate limiting (using both email and IP for better protection)
    const identifier = `${email}_${requestIp || 'unknown'}`;
    if (this.isRateLimited(identifier)) {
      throw new Error('Email rate limit exceeded. Please try again later.');
    }
    
    // Record this attempt regardless of success or failure
    this.recordEmailAttempt(identifier);
    
    // Ensure transporter is set up
    if (!this.transporter) {
      this.setupTransporter();
      if (!this.transporter) {
        throw new Error('Email service is unavailable');
      }
    }
    
    try {
      // Sanitize inputs to prevent XSS
      const sanitizedTitle = sanitizeHtml(compositionTitle || 'EONTA Composition');
      
      // Generate the path map image
      let pathMapUrl = null;
      try {
        pathMapUrl = await pathMapGenerator.generatePathMapImage(recording, composition);
      } catch (mapError) {
        console.error('Error generating path map:', mapError);
        // Continue without map - non-critical error
      }
      
      // Format duration for display
      const durationMinutes = Math.floor((recording?.duration || 0) / 1000 / 60);
      const durationSeconds = Math.floor(((recording?.duration || 0) / 1000) % 60);
      const formattedDuration = `${durationMinutes}:${durationSeconds.toString().padStart(2, '0')}`;
      
      // Format date safely
      const formattedDate = expiresAt.toLocaleDateString();
      
      // Calculate statistics for the email
      const distance = Math.round(recording?.stats?.totalDistance || 0);
      const formattedDistance = distance < 1000 
        ? `${distance} meters` 
        : `${(distance / 1000).toFixed(2)} km`;
      
      const uniqueRegions = recording?.stats?.uniqueRegionsVisited || 0;
      const startTime = new Date(recording?.startTime || Date.now()).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });
      const endTime = new Date(recording?.endTime || Date.now()).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });
      
      // Compose email HTML - use template literal for better readability
      const emailHtml = `
        <div style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; color: #333;">
          <h1 style="color: #4a90e2; margin-bottom: 20px;">Your EONTA Journey</h1>
          
          <p>Thank you for experiencing <strong>${sanitizedTitle}</strong>!</p>
          
          <p>We've created a unique audio composition based on your journey through this sound installation. Below you'll find both your audio composition and a map of your path.</p>
          
          <div style="background-color: #f9f9f9; border-radius: 8px; padding: 20px; margin: 25px 0;">
            <h2 style="font-size:

================
File: server/services/AudioConverter.js
================
const ffmpeg = require('fluent-ffmpeg');
const tmp = require('tmp');
const fs = require('fs');
const path = require('path');

/**
 * AudioConverter service for EONTA
 * Handles conversion of audio files to optimized MP3 format
 */
class AudioConverter {
  /**
   * Convert audio file to optimized MP3 format for web streaming
   * 
   * @param {Buffer} fileBuffer - The original audio file as a buffer
   * @param {string} originalFilename - Original filename
   * @param {string} originalMimetype - Original mimetype
   * @returns {Promise<{buffer: Buffer, filename: string, mimetype: string}>} - Converted file info
   */
  convertToOptimizedFormat(fileBuffer, originalFilename, originalMimetype) {
    return new Promise((resolve, reject) => {
      // Create temporary input file
      const inputTmpFile = tmp.fileSync({ postfix: path.extname(originalFilename) });
      fs.writeFileSync(inputTmpFile.name, fileBuffer);
      
      // Create temporary output file for MP3
      const outputTmpFile = tmp.fileSync({ postfix: '.mp3' });
      
      // Setup conversion based on original file type
      const command = ffmpeg(inputTmpFile.name);
      
      // Set output quality options - 192kbps is a good balance for audio quality and file size
      command
        .noVideo()
        .audioCodec('libmp3lame')
        .audioBitrate(192)
        .audioChannels(2)
        .audioFrequency(44100)
        .format('mp3')
        .output(outputTmpFile.name)
        .on('end', () => {
          // Read the converted file
          try {
            const convertedBuffer = fs.readFileSync(outputTmpFile.name);
            
            // Generate new filename (preserving original name but with mp3 extension)
            const filename = `${path.basename(originalFilename, path.extname(originalFilename))}.mp3`;
            
            // Clean up temp files
            inputTmpFile.removeCallback();
            outputTmpFile.removeCallback();
            
            resolve({
              buffer: convertedBuffer,
              filename: filename,
              mimetype: 'audio/mpeg'
            });
          } catch (err) {
            reject(err);
          }
        })
        .on('error', (err) => {
          // Clean up temp files
          inputTmpFile.removeCallback();
          outputTmpFile.removeCallback();
          reject(err);
        })
        .run();
    });
  }

  /**
   * Determine if file conversion is needed
   * 
   * @param {string} mimetype - The original file's mimetype
   * @returns {boolean} - Whether conversion is needed
   */
  isConversionNeeded(mimetype) {
    // If it's already an MP3, no need to convert
    if (mimetype === 'audio/mpeg' || mimetype === 'audio/mp3') {
      return false;
    }
    
    return true;
  }
}

module.exports = new AudioConverter();

================
File: docs/eonta-structure-summary.md
================
# EONTA System Architecture

This document outlines the modernized EONTA application architecture, ensuring alignment with the original thesis vision while incorporating security enhancements and performance optimizations.

## Core Architecture

EONTA maintains its original architecture as described in the thesis, with these key components:

### Server-Side Components

1. **Node.js Server**
   - Serves the web application assets
   - Handles API requests to MongoDB
   - Manages authentication and security
   - Processes audio files and boundary data

2. **MongoDB Database**
   - Stores audio boundary coordinates
   - Saves composition metadata
   - Maintains user accounts and preferences
   - Uses secure schemas with validation

3. **Amazon S3 Storage**
   - Securely hosts audio files
   - Generates pre-signed URLs for access control
   - Provides reliable cloud storage for compositions

4. **Path Map Generator**
   - Generates visual maps of user paths
   - Creates shareable journey visualizations
   - Integrates with Google Maps API

### Client-Side Components

1. **Core Services**
   - **EnhancedAudioService**: Handles audio playback with Web Audio API
   - **PathRecorderService**: Manages GPS position tracking
   - **BoundaryTransitionManager**: Controls audio transitions between regions
   - **MapUtils**: Provides geospatial calculations and polygon management

2. **User Interface Components**
   - **EontaCompositionViewer**: Main interface for composition management
   - **PathRecorderUI**: Interface for recording and sharing journeys
   - **BoundaryTransitionSettings**: Controls for audio transition behavior

## Audio System

The audio system remains true to the original concept with these key features:

1. **Boundary-Based Triggering**
   - Audio files play when user enters defined boundaries
   - Smooth transitions between regions
   - Support for overlapping regions with crossfades
   - Spatial audio effects based on position

2. **Audio Processing Features**
   - Volume fading for smooth transitions
   - Filter effects (lowpass, highpass)
   - Reverb and delay processing
   - Pitch shifting and spatial audio

3. **Performance Optimizations**
   - Efficient audio buffer management
   - Optimized transition calculations
   - Memory leak prevention
   - Mobile-friendly playback

## Geospatial Features

The mapping and geospatial functionality includes:

1. **Google Maps Integration**
   - Interactive map for composing boundaries
   - Accurate GPS position tracking
   - Polygon drawing tools
   - Boundary visualization

2. **Path Recording**
   - Records user journeys through compositions
   - Creates shareable composition experiences
   - Generates visual path maps
   - Captures audio experiences

## Security Enhancements

The modernized application includes these security improvements:

1. **Input Validation**
   - Coordinate validation for boundaries
   - Audio file validation
   - Secure URL handling
   - Parameter sanitization

2. **Dependency Security**
   - Updated vulnerable libraries
   - Secure package overrides
   - Minimized external dependencies
   - Proper version constraints

3. **Data Security**
   - Secure MongoDB schemas
   - Proper AWS credential handling
   - Sanitized error messages
   - Secure file operations

4. **User Privacy**
   - Optional location tracking
   - Minimal data collection
   - Secure sharing mechanisms
   - Clear user controls

## System Flow

### Composition Creation Process

1. User navigates to a location on the map
2. User creates boundaries using the polygon drawing tool
3. User uploads audio files for each boundary
4. User adjusts transition settings for each boundary
5. Composition is saved to the database with audio files to S3

### Playback Experience Process

1. User navigates to a saved composition
2. EONTA loads the composition boundaries and audio references
3. User's GPS position is tracked in real-time
4. Audio playback is triggered when user enters boundaries
5. Transitions are applied based on position and movement
6. Path recording captures the journey experience

## Modernization Benefits

The modernized EONTA platform preserves the original vision while adding:

1. **Enhanced Security**: Protection against common vulnerabilities
2. **Improved Performance**: Faster loading and smoother playback
3. **Better Mobile Support**: Optimized for modern mobile browsers
4. **Error Resilience**: Graceful handling of network and device issues
5. **Accessibility**: Improved interface for all users

This architecture maintains fidelity to the original thesis vision while ensuring the application is secure, performant, and ready for modern web environments.

================
File: docs/installation-guide.md
================
# EONTA Installation and Setup Guide

This guide will help you set up and run your modernized EONTA application with all security enhancements.

## Prerequisites

Before starting, ensure you have the following installed:

- Node.js 14 or higher
- MongoDB 4.4 or higher
- Git
- npm (comes with Node.js)
- Bower (`npm install -g bower`)
- Gulp (`npm install -g gulp-cli`)

You'll also need:
- Google Maps API key
- AWS account with S3 access
- MongoDB database (local or cloud)

## Installation Steps

### 1. Clone the Repository

```bash
git clone https://github.com/fotopvj/eonta2.git
cd eonta2
```

### 2. Set Up Environment Variables

```bash
cp .env.example .env
```

Open the `.env` file and fill in your specific configuration values including:
- MongoDB connection string
- Google Maps API key
- AWS credentials
- Email settings (if needed)

### 3. Install Dependencies with Security Fixes

```bash
# Install server dependencies with security overrides
npm install

# This will also automatically run the postinstall script to install bower components
```

### 4. Build the Client-Side Assets

```bash
npm run build
```

### 5. Start MongoDB (if using locally)

```bash
# Open a new terminal and run:
mongod
```

### 6. Start the Development Server

```bash
npm run dev
```

The application should now be running at http://localhost:3000 (or whatever port you specified in your .env file).

## Verifying the Installation

1. Navigate to http://localhost:3000 in your browser
2. Allow location access when prompted
3. You should see the EONTA map interface load
4. Try creating a simple audio boundary with a test audio file

## Troubleshooting

### MongoDB Connection Issues

If you encounter MongoDB connection issues:

```bash
# Check MongoDB is running
mongo --eval "db.version()"

# Verify your connection string in .env file
# For local installs, use: mongodb://localhost:27017/eonta
```

### Google Maps API Issues

If the map doesn't load:

1. Check your API key in the .env file
2. Ensure your Google Maps API key has the following APIs enabled:
   - Maps JavaScript API
   - Geocoding API
   - Places API

### AWS S3 Issues

If audio upload fails:

1. Verify your AWS credentials in the .env file
2. Ensure your S3 bucket exists and has proper permissions
3. Check CORS configuration on your S3 bucket

## Deploying to Production

For production deployment:

1. Set `NODE_ENV=production` in your .env file
2. Use a process manager like PM2:
   ```bash
   npm install -g pm2
   pm2 start server/app.js --name eonta
   ```

3. Set up proper SSL with a service like Let's Encrypt
4. Configure your web server (Nginx/Apache) as a reverse proxy

## Security Considerations

The modernized EONTA application includes several security enhancements:

1. **Package Security**:
   - Vulnerable dependencies have been updated
   - Security overrides have been applied
   - Minimal external dependencies are used

2. **API Security**:
   - Rate limiting is implemented for sensitive endpoints
   - Input validation is applied to all user inputs
   - Secure authentication with JWT

3. **Data Security**:
   - MongoDB schema validation
   - Secure AWS credential handling
   - HTTPS enforcement in production

## Maintaining Your Installation

To keep your EONTA installation secure:

1. Run regular security audits:
   ```bash
   npm audit
   ```

2. Apply security fixes when available:
   ```bash
   npm audit fix
   ```

3. Update dependencies regularly:
   ```bash
   npm update
   ```

4. Monitor logs for suspicious activity
5. Back up your MongoDB database regularly

## Getting Help

If you encounter any issues with your EONTA installation, please:

1. Check the troubleshooting section above
2. Review the error logs in the console
3. Refer to the thesis documentation for conceptual understanding
4. Open an issue on the GitHub repository with detailed error information

---

This modernized EONTA platform preserves the original vision of your thesis while adding enhanced security, improved performance, and better compatibility with modern browsers and devices. Enjoy creating immersive audio environments!

================
File: docs/ffmpeg-install-updated.md
================
# FFmpeg Installation for EONTA

FFmpeg is required for the audio conversion functionality in EONTA. This guide explains how to install it on different platforms.

## Ubuntu/Debian

```bash
sudo apt update
sudo apt install ffmpeg
```

Verify installation:
```bash
ffmpeg -version
```

## macOS

Using Homebrew:
```bash
brew install ffmpeg
```

## Windows

1. Download the latest FFmpeg build from https://ffmpeg.org/download.html#build-windows
2. Extract the downloaded zip file
3. Add the `bin` folder to your system PATH environment variable
4. Verify installation by opening a new command prompt and typing:
   ```
   ffmpeg -version
   ```

## Heroku Deployment

For Heroku deployment, you'll need to add the FFmpeg buildpack:

```bash
heroku buildpacks:add https://github.com/jonathanong/heroku-buildpack-ffmpeg-latest.git
```

## After Installing FFmpeg

After installing FFmpeg, you'll need to install the Node.js packages that interface with it:

```bash
npm install fluent-ffmpeg tmp --save
```

These packages are already included in the updated package.json, so if you've run `npm install` after updating that file, you should be good to go.

## Troubleshooting

If you encounter issues with FFmpeg:

1. Ensure FFmpeg is installed and available in your PATH
2. Try running `ffmpeg -version` to confirm it's properly installed
3. Make sure you have the necessary permissions to execute FFmpeg
4. Check that the temporary directories used by the application are writable

## For Development

When testing audio conversion locally:
1. Use smaller audio files initially
2. Check the console logs for conversion progress and errors
3. Verify that converted files are being properly uploaded to S3

================
File: docs/render-deployment-guide.md
================
# Deploying EONTA to Render

This guide will walk you through deploying your EONTA application to Render.

## Prerequisites

1. A [Render account](https://render.com) (you can sign up using GitHub)
2. Your EONTA application code in a GitHub repository
3. AWS S3 bucket already set up
4. MongoDB database already set up (or you can create one through Render)

## Deployment Steps

### 1. Push Your Code to GitHub

Make sure your local changes are pushed to your GitHub repository:

```bash
git add .
git commit -m "Prepare for Render deployment"
git push
```

### 2. Create a New Web Service on Render

1. Log into your Render dashboard: https://dashboard.render.com/
2. Click on "New" and select "Web Service"
3. Connect your GitHub repository
4. Configure your service:
   - **Name**: eonta
   - **Environment**: Node
   - **Build Command**: `chmod +x build.sh && ./build.sh`
   - **Start Command**: `npm start`

### 3. Configure Environment Variables

You'll need to set up the following environment variables in the Render dashboard:

- `NODE_ENV`: production
- `PORT`: 3000
- `MONGODB_URI`: Your MongoDB connection string
- `AWS_ACCESS_KEY_ID`: Your AWS access key
- `AWS_SECRET_ACCESS_KEY`: Your AWS secret key
- `AWS_REGION`: Your AWS region (e.g., us-east-1)
- `S3_BUCKET_NAME`: Your S3 bucket name
- `JWT_SECRET`: Auto-generated secure string
- `JWT_EXPIRATION`: 7d
- `CORS_ALLOWED_ORIGINS`: https://eonta.onrender.com
- `SESSION_SECRET`: Auto-generated secure string
- `MAX_AUDIO_FILE_SIZE_MB`: 30
- `ALLOWED_AUDIO_FORMATS`: wav,mp3,m4a,ogg,aac,flac

### 4. Deploy

Click on "Create Web Service" to start the deployment process. Render will build and deploy your application automatically.

## Setting Up a MongoDB Database on Render (Optional)

If you don't have a MongoDB database yet, you can create one through Render:

1. In your Render dashboard, click "New" and select "PostgreSQL"
2. Configure your database settings
3. After creation, copy the internal connection string
4. Update your application's `MONGODB_URI` environment variable with this connection string

## Continuous Deployment

Render automatically deploys your application whenever you push changes to your GitHub repository. No additional configuration is needed.

## Monitoring

You can monitor your application logs and metrics through the Render dashboard:

1. Go to your Web Service in the Render dashboard
2. Click on "Logs" to view application logs
3. Click on "Metrics" to view performance metrics

## Troubleshooting

If you encounter any issues during deployment:

1. Check your application logs in the Render dashboard
2. Verify that all environment variables are set correctly
3. Make sure your `build.sh` script is executable (`chmod +x build.sh`)
4. Check if FFmpeg was installed correctly by examining the build logs

## Custom Domain (Optional)

To use a custom domain with your Render deployment:

1. Go to your Web Service in the Render dashboard
2. Click on "Settings" and scroll to "Custom Domain"
3. Follow the instructions to add and verify your domain

================
File: client/index.html
================
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>EONTA - GPS-Based Audio Platform</title>
  <link rel="stylesheet" href="assets/css/main.css">
</head>
<body>
  <nav class="navbar">
    <div class="navbar-brand">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 500 150" width="120" height="36">
        <!-- Background Sound Waves -->
        <path d="M45,75 C60,45 75,105 90,75 C105,45 120,105 135,75" fill="none" stroke="#7EB3F1" stroke-width="4" stroke-linecap="round" opacity="0.5"/>
        <path d="M30,75 C50,30 70,120 90,75 C110,30 130,120 150,75" fill="none" stroke="#5B48D9" stroke-width="5" stroke-linecap="round" opacity="0.4"/>
        <path d="M20,75 C45,20 70,130 95,75 C120,20 145,130 170,75" fill="none" stroke="#4A90E2" stroke-width="6" stroke-linecap="round" opacity="0.3"/>
        
        <!-- Location Pin with Sound Wave -->
        <circle cx="200" cy="75" r="25" fill="#4A90E2"/>
        <path d="M200,50 L200,100" stroke="white" stroke-width="3" stroke-linecap="round"/>
        <circle cx="200" cy="60" r="4" fill="white"/>
        
        <!-- Sound Waves from Pin -->
        <path d="M215,75 C225,65 235,85 245,75" fill="none" stroke="white" stroke-width="2.5" stroke-linecap="round"/>
        <path d="M220,75 C235,55 250,95 265,75" fill="none" stroke="white" stroke-width="2" stroke-linecap="round"/>
        <path d="M225,75 C245,45 265,105 285,75" fill="none" stroke="white" stroke-width="1.5" stroke-linecap="round"/>
        
        <!-- Text "EONTA" -->
        <text x="300" y="95" font-family="Arial, sans-serif" font-size="55" font-weight="bold" fill="#4A90E2">EONTA</text>
      </svg>
    </div>
    <ul class="navbar-nav">
      <li><a href="#">Home</a></li>
      <li><a href="#">Compositions</a></li>
      <li><a href="#">Settings</a></li>
    </ul>
  </nav>

  <div id="map-container">
    <!-- Map will be loaded here by Google Maps API -->
    <p style="text-align: center; padding-top: 40vh; color: #666;">
      Loading map... Please ensure your Google Maps API key is configured correctly.
    </p>
  </div>

  <div class="path-recorder-control">
    <button class="record-btn">
      <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
        <circle cx="12" cy="12" r="6"></circle>
      </svg>
    </button>
  </div>

  <script src="src/app.js"></script>
  <!-- Google Maps API -->
  <script async defer src="https://maps.googleapis.com/maps/api/js?key=YOUR_API_KEY&callback=initMap"></script>
</body>
</html>

================
File: client/assets/css/main.css
================
/* EONTA3 Main Stylesheet
 * A clean, modern design for the GPS-based audio platform
 */

:root {
  /* Color palette */
  --primary-color: #4a90e2;
  --primary-dark: #3a7bc8;
  --primary-light: #7eb3f1;
  --accent-color: #5b48d9;
  --accent-light: #7b6ee1;
  --success-color: #32c787;
  --warning-color: #f7c744;
  --danger-color: #e74c3c;
  --text-color: #333333;
  --text-light: #666666;
  --background-color: #f8f9fa;
  --card-color: #ffffff;
  --border-color: #e0e0e0;
  
  /* Typography */
  --font-family-base: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
  --font-family-heading: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
  
  /* Spacing */
  --spacing-xs: 0.25rem;
  --spacing-sm: 0.5rem;
  --spacing-md: 1rem;
  --spacing-lg: 1.5rem;
  --spacing-xl: 2.5rem;
  
  /* Borders */
  --border-radius-sm: 0.25rem;
  --border-radius-md: 0.5rem;
  --border-radius-lg: 0.75rem;
  
  /* Shadows */
  --shadow-sm: 0 2px 4px rgba(0, 0, 0, 0.05);
  --shadow-md: 0 4px 6px rgba(0, 0, 0, 0.1);
  --shadow-lg: 0 10px 15px rgba(0, 0, 0, 0.1);
}

/* Dark mode variables */
.dark {
  --primary-color: #5a9aec;
  --primary-dark: #4a86d0;
  --primary-light: #8abbf2;
  --accent-color: #6f59f7;
  --accent-light: #8a77f5;
  --text-color: #f0f0f0;
  --text-light: #c0c0c0;
  --background-color: #121212;
  --card-color: #1e1e1e;
  --border-color: #333333;
  --shadow-sm: 0 2px 4px rgba(0, 0, 0, 0.2);
  --shadow-md: 0 4px 6px rgba(0, 0, 0, 0.25);
  --shadow-lg: 0 10px 15px rgba(0, 0, 0, 0.25);
}

/* Base styles */
html, body {
  font-family: var(--font-family-base);
  font-size: 16px;
  line-height: 1.5;
  color: var(--text-color);
  background-color: var(--background-color);
  margin: 0;
  padding: 0;
  height: 100%;
  width: 100%;
  overflow-x: hidden;
}

/* Common elements */
h1, h2, h3, h4, h5, h6 {
  font-family: var(--font-family-heading);
  font-weight: 600;
  margin-top: 0;
  margin-bottom: var(--spacing-md);
  line-height: 1.2;
}

h1 {
  font-size: 2rem;
}

h2 {
  font-size: 1.5rem;
}

h3 {
  font-size: 1.25rem;
}

a {
  color: var(--primary-color);
  text-decoration: none;
  transition: color 0.2s ease-in-out;
}

a:hover {
  color: var(--primary-dark);
  text-decoration: underline;
}

button, .btn {
  display: inline-block;
  font-weight: 500;
  text-align: center;
  vertical-align: middle;
  user-select: none;
  padding: 0.5rem 1rem;
  font-size: 1rem;
  line-height: 1.5;
  border-radius: var(--border-radius-md);
  transition: all 0.2s ease-in-out;
  cursor: pointer;
  border: 1px solid transparent;
}

.btn-primary {
  background-color: var(--primary-color);
  border-color: var(--primary-color);
  color: white;
}

.btn-primary:hover {
  background-color: var(--primary-dark);
  border-color: var(--primary-dark);
}

.btn-secondary {
  background-color: transparent;
  border-color: var(--border-color);
  color: var(--text-color);
}

.btn-secondary:hover {
  background-color: rgba(0, 0, 0, 0.05);
}

.dark .btn-secondary:hover {
  background-color: rgba(255, 255, 255, 0.05);
}

.btn-danger {
  background-color: var(--danger-color);
  border-color: var(--danger-color);
  color: white;
}

.btn-danger:hover {
  background-color: #c0392b;
  border-color: #c0392b;
}

/* Layout */
.container {
  width: 100%;
  max-width: 1200px;
  margin: 0 auto;
  padding: 0 var(--spacing-md);
}

.row {
  display: flex;
  flex-wrap: wrap;
  margin-right: -var(--spacing-md);
  margin-left: -var(--spacing-md);
}

.col {
  flex: 1 0 0%;
  padding: 0 var(--spacing-md);
}

/* Card Component */
.card {
  background-color: var(--card-color);
  border-radius: var(--border-radius-md);
  box-shadow: var(--shadow-sm);
  margin-bottom: var(--spacing-lg);
  overflow: hidden;
}

.card-header {
  padding: var(--spacing-md) var(--spacing-lg);
  border-bottom: 1px solid var(--border-color);
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.card-body {
  padding: var(--spacing-lg);
}

.card-footer {
  padding: var(--spacing-md) var(--spacing-lg);
  border-top: 1px solid var(--border-color);
}

/* Form elements */
input, select, textarea {
  display: block;
  width: 100%;
  padding: 0.5rem 0.75rem;
  font-size: 1rem;
  line-height: 1.5;
  color: var(--text-color);
  background-color: var(--card-color);
  background-clip: padding-box;
  border: 1px solid var(--border-color);
  border-radius: var(--border-radius-sm);
  transition: border-color 0.15s ease-in-out, box-shadow 0.15s ease-in-out;
}

input:focus, select:focus, textarea:focus {
  color: var(--text-color);
  background-color: var(--card-color);
  border-color: var(--primary-light);
  outline: 0;
  box-shadow: 0 0 0 0.2rem rgba(74, 144, 226, 0.25);
}

.dark input, .dark select, .dark textarea {
  background-color: #252525;
  color: var(--text-color);
  border-color: #444;
}

label {
  display: inline-block;
  margin-bottom: 0.5rem;
  font-weight: 500;
}

.form-group {
  margin-bottom: var(--spacing-md);
}

/* Navigation */
.navbar {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: var(--spacing-md) var(--spacing-lg);
  background-color: var(--card-color);
  box-shadow: var(--shadow-sm);
}

.navbar-brand {
  font-size: 1.5rem;
  font-weight: 700;
  color: var(--primary-color);
  display: flex;
  align-items: center;
}

.navbar-brand img {
  height: 32px;
  margin-right: var(--spacing-sm);
}

.navbar-nav {
  display: flex;
  list-style: none;
  margin: 0;
  padding: 0;
}

.navbar-nav li {
  margin-left: var(--spacing-md);
}

.navbar-nav a {
  color: var(--text-color);
  font-weight: 500;
}

.navbar-nav a:hover {
  color: var(--primary-color);
}

/* EONTA specific styles */
#map-container {
  width: 100%;
  height: calc(100vh - 60px);
  position: relative;
}

.map-controls {
  position: absolute;
  top: var(--spacing-md);
  right: var(--spacing-md);
  z-index: 10;
  display: flex;
  flex-direction: column;
  gap: var(--spacing-sm);
}

.map-controls button {
  width: 40px;
  height: 40px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  background-color: white;
  border: none;
  box-shadow: var(--shadow-md);
}

.audio-boundaries-list {
  max-height: 300px;
  overflow-y: auto;
  border: 1px solid var(--border-color);
  border-radius: var(--border-radius-md);
}

.audio-boundary-item {
  padding: var(--spacing-sm) var(--spacing-md);
  border-bottom: 1px solid var(--border-color);
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.audio-boundary-item:last-child {
  border-bottom: none;
}

.audio-boundary-item.active {
  background-color: rgba(74, 144, 226, 0.1);
}

.audio-boundary-item.playing {
  position: relative;
}

.audio-boundary-item.playing::before {
  content: '';
  display: block;
  width: 8px;
  height: 8px;
  border-radius: 50%;
  background-color: var(--primary-color);
  position: absolute;
  left: 8px;
  top: 50%;
  transform: translateY(-50%);
}

.transition-settings-panel {
  border: 1px solid var(--border-color);
  border-radius: var(--border-radius-md);
  padding: var(--spacing-md);
  margin-bottom: var(--spacing-lg);
}

.path-recorder-control {
  position: fixed;
  bottom: var(--spacing-lg);
  right: var(--spacing-lg);
  z-index: 100;
}

/* Path Recorder Button */
.record-btn {
  width: 60px;
  height: 60px;
  border-radius: 50%;
  background-color: var(--danger-color);
  color: white;
  display: flex;
  align-items: center;
  justify-content: center;
  border: none;
  box-shadow: var(--shadow-lg);
  transition: all 0.3s ease;
}

.record-btn:hover {
  transform: scale(1.05);
}

.record-btn.recording {
  animation: pulse 2s infinite;
}

@keyframes pulse {
  0% {
    box-shadow: 0 0 0 0 rgba(231, 76, 60, 0.7);
  }
  70% {
    box-shadow: 0 0 0 10px rgba(231, 76, 60, 0);
  }
  100% {
    box-shadow: 0 0 0 0 rgba(231, 76, 60, 0);
  }
}

/* Notifications */
.notification {
  position: fixed;
  top: var(--spacing-lg);
  right: var(--spacing-lg);
  padding: var(--spacing-md) var(--spacing-lg);
  border-radius: var(--border-radius-md);
  background-color: var(--card-color);
  box-shadow: var(--shadow-md);
  z-index: 1000;
  max-width: 350px;
  animation: slideIn 0.3s forwards;
}

.notification.success {
  border-left: 4px solid var(--success-color);
}

.notification.error {
  border-left: 4px solid var(--danger-color);
}

.notification.info {
  border-left: 4px solid var(--primary-color);
}

.notification.warning {
  border-left: 4px solid var(--warning-color);
}

@keyframes slideIn {
  0% {
    transform: translateX(100%);
    opacity: 0;
  }
  100% {
    transform: translateX(0);
    opacity: 1;
  }
}

/* Modal */
.modal-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 1000;
}

.modal {
  background-color: var(--card-color);
  border-radius: var(--border-radius-lg);
  width: 90%;
  max-width: 500px;
  box-shadow: var(--shadow-lg);
  overflow: hidden;
}

.modal-header {
  padding: var(--spacing-md) var(--spacing-lg);
  border-bottom: 1px solid var(--border-color);
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.modal-body {
  padding: var(--spacing-lg);
}

.modal-footer {
  padding: var(--spacing-md) var(--spacing-lg);
  border-top: 1px solid var(--border-color);
  display: flex;
  justify-content: flex-end;
  gap: var(--spacing-sm);
}

/* Responsive adjustments */
@media (max-width: 768px) {
  .container {
    padding: 0 var(--spacing-sm);
  }
  
  .card-header, .card-body, .card-footer {
    padding: var(--spacing-md);
  }
  
  .navbar {
    padding: var(--spacing-sm) var(--spacing-md);
  }
  
  .path-recorder-control {
    bottom: var(--spacing-md);
    right: var(--spacing-md);
  }
  
  .notification {
    top: var(--spacing-md);
    right: var(--spacing-md);
    left: var(--spacing-md);
    max-width: none;
  }
}

/* Utility Classes */
.text-center { text-align: center; }
.text-right { text-align: right; }
.text-primary { color: var(--primary-color); }
.text-success { color: var(--success-color); }
.text-warning { color: var(--warning-color); }
.text-danger { color: var(--danger-color); }
.text-muted { color: var(--text-light); }

.bg-primary { background-color: var(--primary-color); }
.bg-success { background-color: var(--success-color); }
.bg-warning { background-color: var(--warning-color); }
.bg-danger { background-color: var(--danger-color); }

.mb-sm { margin-bottom: var(--spacing-sm); }
.mb-md { margin-bottom: var(--spacing-md); }
.mb-lg { margin-bottom: var(--spacing-lg); }
.mt-sm { margin-top: var(--spacing-sm); }
.mt-md { margin-top: var(--spacing-md); }
.mt-lg { margin-top: var(--spacing-lg); }

.d-flex { display: flex; }
.justify-between { justify-content: space-between; }
.items-center { align-items: center; }
.flex-col { flex-direction: column; }
.flex-grow { flex-grow: 1; }

.w-full { width: 100%; }
.h-full { height: 100%; }

================
File: client/assets/img/logo.svg
================
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 500 150" width="500" height="150">
  <!-- Background Sound Waves -->
  <path d="M45,75 C60,45 75,105 90,75 C105,45 120,105 135,75" fill="none" stroke="#7EB3F1" stroke-width="4" stroke-linecap="round" opacity="0.5"/>
  <path d="M30,75 C50,30 70,120 90,75 C110,30 130,120 150,75" fill="none" stroke="#5B48D9" stroke-width="5" stroke-linecap="round" opacity="0.4"/>
  <path d="M20,75 C45,20 70,130 95,75 C120,20 145,130 170,75" fill="none" stroke="#4A90E2" stroke-width="6" stroke-linecap="round" opacity="0.3"/>
  
  <!-- Location Pin with Sound Wave -->
  <circle cx="200" cy="75" r="25" fill="#4A90E2"/>
  <path d="M200,50 L200,100" stroke="white" stroke-width="3" stroke-linecap="round"/>
  <circle cx="200" cy="60" r="4" fill="white"/>
  
  <!-- Sound Waves from Pin -->
  <path d="M215,75 C225,65 235,85 245,75" fill="none" stroke="white" stroke-width="2.5" stroke-linecap="round"/>
  <path d="M220,75 C235,55 250,95 265,75" fill="none" stroke="white" stroke-width="2" stroke-linecap="round"/>
  <path d="M225,75 C245,45 265,105 285,75" fill="none" stroke="white" stroke-width="1.5" stroke-linecap="round"/>
  
  <!-- Text "EONTA" -->
  <text x="300" y="95" font-family="Arial, sans-serif" font-size="55" font-weight="bold" fill="#4A90E2">EONTA</text>
  
  <!-- Tagline -->
  <text x="305" y="115" font-family="Arial, sans-serif" font-size="14" fill="#5B48D9">Immersive Audio Environments</text>
</svg>

================
File: client/src/app.js
================
// Initialize map when Google Maps API loads
function initMap() {
  // Check if Google Maps API is available
  if (typeof google === 'undefined' || typeof google.maps === 'undefined') {
    console.error('Google Maps API not loaded');
    document.getElementById('map-container').innerHTML = 
      '<div style="text-align: center; padding-top: 40vh; color: #666;">' +
      '<p>Could not load Google Maps. Please check your API key.</p>' +
      '</div>';
    return;
  }

  // Create a map centered at a default location
  const map = new google.maps.Map(document.getElementById('map-container'), {
    center: { lat: 40.730610, lng: -73.935242 }, // New York City
    zoom: 13,
    mapTypeId: google.maps.MapTypeId.ROADMAP,
    mapTypeControl: true,
    mapTypeControlOptions: {
      style: google.maps.MapTypeControlStyle.HORIZONTAL_BAR,
      position: google.maps.ControlPosition.TOP_RIGHT
    },
    zoomControl: true,
    zoomControlOptions: {
      position: google.maps.ControlPosition.RIGHT_CENTER
    },
    scaleControl: true,
    streetViewControl: true,
    streetViewControlOptions: {
      position: google.maps.ControlPosition.RIGHT_BOTTOM
    },
    fullscreenControl: true
  });

  // Try HTML5 geolocation to center the map on user's location
  if (navigator.geolocation) {
    navigator.geolocation.getCurrentPosition(
      (position) => {
        const pos = {
          lat: position.coords.latitude,
          lng: position.coords.longitude,
        };
        map.setCenter(pos);
        
        // Add a marker at the user's location
        new google.maps.Marker({
          position: pos,
          map: map,
          title: "Your Location"
        });
      },
      () => {
        console.warn("Geolocation failed or was denied by the user");
      }
    );
  }
}

// Record button functionality (simulation)
document.addEventListener('DOMContentLoaded', function() {
  document.querySelector('.record-btn').addEventListener('click', function() {
    this.classList.toggle('recording');
    if (this.classList.contains('recording')) {
      alert('Recording started! In a full implementation, this would track your path.');
    } else {
      alert('Recording stopped! In a full implementation, this would save your path data.');
    }
  });
});

================
File: client/src/components/BoundaryTransitionSettings.jsx
================
import React, { useState, useEffect, useCallback, useRef } from 'react';
import { Sliders, ChevronDown, ChevronUp, Check, Play, Volume2, Music, Filter, AlertCircle } from 'lucide-react';

/**
 * Boundary Transition Settings Component
 * Manages audio transition settings for region boundaries
 */
const BoundaryTransitionSettings = ({ boundary, onChange, onPreview }) => {
  // If no boundary provided, use sample data for demonstration
  const defaultBoundary = {
    id: "region1",
    name: "Fountain Area",
    transitionSettings: {
      fadeInLength: 1.5,
      fadeOutLength: 2.0,
      fadeInType: "volume_fade",
      fadeOutType: "lowpass_filter",
      transitionRadius: 10,
      blendingEnabled: true,
      crossfadeOverlap: true,
      advancedSettings: {
        lowpassFrequency: {
          start: 20000,
          end: 500
        },
        highpassFrequency: {
          start: 20,
          end: 2000
        },
        reverbMix: {
          start: 0.1,
          end: 0.7
        }
      }
    }
  };
  
  const [boundaryData, setBoundaryData] = useState(boundary || defaultBoundary);
  const [expanded, setExpanded] = useState(false);
  const [activeTab, setActiveTab] = useState('entry');
  const [settings, setSettings] = useState(boundaryData.transitionSettings);
  const [error, setError] = useState(null);
  const prevBoundaryRef = useRef();
  
  // Update settings when boundary changes
  useEffect(() => {
    if (boundary && boundary.id !== prevBoundaryRef.current?.id) {
      setBoundaryData(boundary);
      setSettings(boundary.transitionSettings);
      prevBoundaryRef.current = boundary;
    }
  }, [boundary]);
  
  // Handle settings change
  const handleChange = useCallback((property, value) => {
    try {
      // Validate input
      if (property === 'transitionRadius') {
        // Ensure transition radius is within reasonable limits
        value = Math.max(1, Math.min(50, value));
      } else if (property === 'fadeInLength' || property === 'fadeOutLength') {
        // Ensure fade lengths are within reasonable limits
        value = Math.max(0.1, Math.min(10, value));
      }
      
      const newSettings = { ...settings, [property]: value };
      setSettings(newSettings);
      
      // Notify parent component
      if (onChange) {
        onChange(newSettings);
      }
      
      // Clear any previous errors
      setError(null);
    } catch (err) {
      console.error('Error updating setting:', err);
      setError(`Failed to update ${property}: ${err.message}`);
    }
  }, [settings, onChange]);
  
  // Handle advanced settings change
  const handleAdvancedChange = useCallback((category, property, value) => {
    try {
      const advancedSettings = { ...settings.advancedSettings };
      
      if (!advancedSettings[category]) {
        advancedSettings[category] = {};
      }
      
      // Validate values based on category
      if (category === 'lowpassFrequency' || category === 'highpassFrequency') {
        // Frequency values should be within audible range
        value = Math.max(20, Math.min(20000, value));
      } else if (category === 'reverbMix') {
        // Mix values should be between 0 and 1
        value = Math.max(0, Math.min(1, value));
      }
      
      advancedSettings[category][property] = value;
      
      const newSettings = { ...settings, advancedSettings };
      setSettings(newSettings);
      
      // Notify parent component
      if (onChange) {
        onChange(newSettings);
      }
      
      // Clear any previous errors
      setError(null);
    } catch (err) {
      console.error('Error updating advanced setting:', err);
      setError(`Failed to update ${category}.${property}: ${err.message}`);
    }
  }, [settings, onChange]);
  
  // Preview transition effect
  const handlePreview = useCallback((transitionType) => {
    if (!onPreview) return;
    
    try {
      onPreview(transitionType, settings);
    } catch (err) {
      console.error('Error previewing transition:', err);
      setError(`Failed to preview transition: ${err.message}`);
    }
  }, [settings, onPreview]);
  
  // Available transition types
  const transitionTypes = [
    { id: 'volume_fade', name: 'Volume Fade', icon: <Volume2 size={16} /> },
    { id: 'lowpass_filter', name: 'Low Pass Filter', icon: <Filter size={16} /> },
    { id: 'highpass_filter', name: 'High Pass Filter', icon: <Filter size={16} /> },
    { id: 'reverb_tail', name: 'Reverb Tail', icon: <Music size={16} /> },
    { id: 'pitch_shift', name: 'Pitch Shift', icon: <Music size={16} /> },
    { id: 'delay_feedback', name: 'Delay Feedback', icon: <Music size={16} /> },
    { id: 'doppler', name: 'Doppler Effect', icon: <Music size={16} /> },
    { id: 'spatial_blend', name: 'Spatial Blend', icon: <Music size={16} /> }
  ];
  
  return (
    <div className="bg-white dark:bg-gray-800 rounded-lg shadow-md w-full max-w-md">
      {/* Header */}
      <div className="p-4 border-b border-gray-200 dark:border-gray-700">
        <div className="flex justify-between items-center mb-1">
          <h2 className="text-lg font-semibold text-gray-800 dark:text-white flex items-center">
            <Sliders size={20} className="mr-2 text-blue-500" />
            Audio Boundary Transitions
          </h2>
          <button
            onClick={() => setExpanded(!expanded)}
            className="text-gray-500 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-200"
            aria-label={expanded ? "Collapse advanced settings" : "Expand advanced settings"}
            aria-expanded={expanded}
          >
            {expanded ? <ChevronUp size={20} /> : <ChevronDown size={20} />}
          </button>
        </div>
        <p className="text-sm text-gray-600 dark:text-gray-400">
          Configure how audio fades in and out as users move through boundaries
        </p>
      </div>
      
      {/* Error display */}
      {error && (
        <div className="mx-4 mt-2 p-2 bg-red-100 dark:bg-red-900/30 text-red-800 dark:text-red-300 text-sm rounded flex items-start">
          <AlertCircle size={16} className="mr-2 mt-0.5 flex-shrink-0" />
          <div>{error}</div>
        </div>
      )}
      
      {/* Basic Controls (always visible) */}
      <div className="p-4">
        <div className="mb-4">
          <label className="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">
            Transition Radius (meters)
          </label>
          <input
            type="range"
            min="1"
            max="50"
            value={settings.transitionRadius}
            onChange={(e) => handleChange('transitionRadius', Number(e.target.value))}
            className="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer dark:bg-gray-700"
            aria-label={`Transition radius: ${settings.transitionRadius} meters`}
          />
          <div className="flex justify-between text-xs text-gray-500 dark:text-gray-400 mt-1">
            <span>1m</span>
            <span>{settings.transitionRadius}m</span>
            <span>50m</span>
          </div>
        </div>
        
        {/* Tabs for Entry/Exit */}
        <div className="flex border-b border-gray-200 dark:border-gray-700 mb-4">
          <button
            className={`py-2 px-4 font-medium text-sm border-b-2 ${
              activeTab === 'entry'
                ? 'border-blue-500 text-blue-600 dark:text-blue-400'
                : 'border-transparent text-gray-500 dark:text-gray-400'
            }`}
            onClick={() => setActiveTab('entry')}
            aria-pressed={activeTab === 'entry'}
          >
            Entry Transition
          </button>
          <button
            className={`py-2 px-4 font-medium text-sm border-b-2 ${
              activeTab === 'exit'
                ? 'border-blue-500 text-blue-600 dark:text-blue-400'
                : 'border-transparent text-gray-500 dark:text-gray-400'
            }`}
            onClick={() => setActiveTab('exit')}
            aria-pressed={activeTab === 'exit'}
          >
            Exit Transition
          </button>
        </div>
        
        {/* Entry/Exit Settings */}
        {activeTab === 'entry' ? (
          <div>
            <div className="mb-4">
              <label className="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">
                Fade In Length (seconds)
              </label>
              <div className="flex items-center">
                <input
                  type="range"
                  min="0.1"
                  max="10"
                  step="0.1"
                  value={settings.fadeInLength}
                  onChange={(e) => handleChange('fadeInLength', Number(e.target.value))}
                  className="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer dark:bg-gray-700"
                  aria-label={`Fade in length: ${settings.fadeInLength.toFixed(1)} seconds`}
                />
                <span className="ml-2 text-sm min-w-12 text-gray-600 dark:text-gray-300">
                  {settings.fadeInLength.toFixed(1)}s
                </span>
              </div>
            </div>
            
            <div className="mb-4">
              <div className="flex justify-between items-center mb-2">
                <label className="block text-sm font-medium text-gray-700 dark:text-gray-300">
                  Fade In Type
                </label>
                <button 
                  onClick={() => handlePreview(settings.fadeInType)}
                  className="text-xs bg-blue-100 hover:bg-blue-200 text-blue-700 dark:bg-blue-900 dark:text-blue-300 dark:hover:bg-blue-800 py-1 px-2 rounded flex items-center"
                  aria-label="Preview fade in effect"
                >
                  <Play size={12} className="mr-1" /> Preview
                </button>
              </div>
              <div className="grid grid-cols-2 gap-2">
                {transitionTypes.map(type => (
                  <button
                    key={`entry-${type.id}`}
                    className={`flex items-center px-3 py-2 rounded-md text-sm ${
                      settings.fadeInType === type.id
                        ? 'bg-blue-100 text-blue-700 dark:bg-blue-900 dark:text-blue-300'
                        : 'bg-gray-100 text-gray-700 dark:bg-gray-700 dark:text-gray-300 hover:bg-gray-200 dark:hover:bg-gray-600'
                    }`}
                    onClick={() => handleChange('fadeInType', type.id)}
                    aria-pressed={settings.fadeInType === type.id}
                  >
                    <span className="mr-2">{type.icon}</span>
                    <span className="truncate">{type.name}</span>
                    {settings.fadeInType === type.id && (
                      <Check size={16} className="ml-auto" />
                    )}
                  </button>
                ))}
              </div>
            </div>
          </div>
        ) : (
          <div>
            <div className="mb-4">
              <label className="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">
                Fade Out Length (seconds)
              </label>
              <div className="flex items-center">
                <input
                  type="range"
                  min="0.1"
                  max="10"
                  step="0.1"
                  value={settings.fadeOutLength}
                  onChange={(e) => handleChange('fadeOutLength', Number(e.target.value))}
                  className="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer dark:bg-gray-700"
                  aria-label={`Fade out length: ${settings.fadeOutLength.toFixed(1)} seconds`}
                />
                <span className="ml-2 text-sm min-w-12 text-gray-600 dark:text-gray-300">
                  {settings.fadeOutLength.toFixed(1)}s
                </span>
              </div>
            </div>
            
            <div className="mb-4">
              <div className="flex justify-between items-center mb-2">
                <label className="block text-sm font-medium text-gray-700 dark:text-gray-300">
                  Fade Out Type
                </label>
                <button 
                  onClick={() => handlePreview(settings.fadeOutType)}
                  className="text-xs bg-blue-100 hover:bg-blue-200 text-blue-700 dark:bg-blue-900 dark:text-blue-300 dark:hover:bg-blue-800 py-1 px-2 rounded flex items-center"
                  aria-label="Preview fade out effect"
                >
                  <Play size={12} className="mr-1" /> Preview
                </button>
              </div>
              <div className="grid grid-cols-2 gap-2">
                {transitionTypes.map(type => (
                  <button
                    key={`exit-${type.id}`}
                    className={`flex items-center px-3 py-2 rounded-md text-sm ${
                      settings.fadeOutType === type.id
                        ? 'bg-blue-100 text-blue-700 dark:bg-blue-900 dark:text-blue-300'
                        : 'bg-gray-100 text-gray-700 dark:bg-gray-700 dark:text-gray-300 hover:bg-gray-200 dark:hover:bg-gray-600'
                    }`}
                    onClick={() => handleChange('fadeOutType', type.id)}
                    aria-pressed={settings.fadeOutType === type.id}
                  >
                    <span className="mr-2">{type.icon}</span>
                    <span className="truncate">{type.name}</span>
                    {settings.fadeOutType === type.id && (
                      <Check size={16} className="ml-auto" />
                    )}
                  </button>
                ))}
              </div>
            </div>
          </div>
        )}
        
        {/* Toggle options */}
        <div className="space-y-2 mb-4 mt-6">
          <div className="flex items-center">
            <input
              type="checkbox"
              id="blendingEnabled"
              checked={settings.blendingEnabled}
              onChange={(e) => handleChange('blendingEnabled', e.target.checked)}
              className="h-4 w-4 text-blue-600 rounded border-gray-300 focus:ring-blue-500 dark:border-gray-600 dark:bg-gray-700"
              aria-label="Enable transition blending"
            />
            <label htmlFor="blendingEnabled" className="ml-2 text-sm text-gray-700 dark:text-gray-300">
              Enable transition blending
            </label>
          </div>
          
          <div className="flex items-center">
            <input
              type="checkbox"
              id="crossfadeOverlap"
              checked={settings.crossfadeOverlap}
              onChange={(e) => handleChange('crossfadeOverlap', e.target.checked)}
              className="h-4 w-4 text-blue-600 rounded border-gray-300 focus:ring-blue-500 dark:border-gray-600 dark:bg-gray-700"
              aria-label="Enable crossfade between overlapping regions"
            />
            <label htmlFor="crossfadeOverlap" className="ml-2 text-sm text-gray-700 dark:text-gray-300">
              Enable crossfade between overlapping regions
            </label>
          </div>
        </div>
      </div>
      
      {/* Advanced Settings (expandable) */}
      {expanded && (
        <div className="p-4 border-t border-gray-200 dark:border-gray-700">
          <h3 className="font-medium text-gray-900 dark:text-white mb-4">
            Advanced Settings
          </h3>
          
          {/* Show specific settings based on selected transition types */}
          {(settings.fadeInType === 'lowpass_filter' || settings.fadeOutType === 'lowpass_filter') && (
            <div className="mb-6">
              <h4 className="text-sm font-medium text-gray-700 dark:text-gray-300 mb-3">
                Low Pass Filter Settings
              </h4>
              
              <div className="space-y-4">
                <div>
                  <label className="block text-xs text-gray-600 dark:text-gray-400 mb-1">
                    Start Frequency (Hz)
                  </label>
                  <div className="flex items-center">
                    <input
                      type="range"
                      min="20"
                      max="20000"
                      step="10"
                      value={settings.advancedSettings.lowpassFrequency.start}
                      onChange={(e) => handleAdvancedChange(
                        'lowpassFrequency',
                        'start',
                        Number(e.target.value)
                      )}
                      className="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer dark:bg-gray-700"
                      aria-label={`Low pass filter start frequency: ${settings.advancedSettings.lowpassFrequency.start} Hz`}
                    />
                    <span className="ml-2 text-xs min-w-16 text-gray-600 dark:text-gray-300">
                      {settings.advancedSettings.lowpassFrequency.start} Hz
                    </span>
                  </div>
                </div>
                
                <div>
                  <label className="block text-xs text-gray-600 dark:text-gray-400 mb-1">
                    End Frequency (Hz)
                  </label>
                  <div className="flex items-center">
                    <input
                      type="range"
                      min="20"
                      max="20000"
                      step="10"
                      value={settings.advancedSettings.lowpassFrequency.end}
                      onChange={(e) => handleAdvancedChange(
                        'lowpassFrequency',
                        'end',
                        Number(e.target.value)
                      )}
                      className="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer dark:bg-gray-700"
                      aria-label={`Low pass filter end frequency: ${settings.advancedSettings.lowpassFrequency.end} Hz`}
                    />
                    <span className="ml-2 text-xs min-w-16 text-gray-600 dark:text-gray-300">
                      {settings.advancedSettings.lowpassFrequency.end} Hz
                    </span>
                  </div>
                </div>
              </div>
            </div>
          )}
          
          {(settings.fadeInType === 'reverb_tail' || settings.fadeOutType === 'reverb_tail') && (
            <div className="mb-6">
              <h4 className="text-sm font-medium text-gray-700 dark:text-gray-300 mb-3">
                Reverb Settings
              </h4>
              
              <div className="space-y-4">
                <div>
                  <label className="block text-xs text-gray-600 dark:text-gray-400 mb-1">
                    Start Mix (Dry/Wet)
                  </label>
                  <div className="flex items-center">
                    <input
                      type="range"
                      min="0"
                      max="1"
                      step="0.01"
                      value={settings.advancedSettings.reverbMix.start}
                      onChange={(e) => handleAdvancedChange(
                        'reverbMix',
                        'start',
                        Number(e.target.value)
                      )}
                      className="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer dark:bg-gray-700"
                      aria-label={`Reverb start mix: ${(settings.advancedSettings.reverbMix.start * 100).toFixed(0)}%`}
                    />
                    <span className="ml-2 text-xs min-w-12 text-gray-600 dark:text-gray-300">
                      {(settings.advancedSettings.reverbMix.start * 100).toFixed(0)}%
                    </span>
                  </div>
                </div>
                
                <div>
                  <label className="block text-xs text-gray-600 dark:text-gray-400 mb-1">
                    End Mix (Dry/Wet)
                  </label>
                  <div className="flex items-center">
                    <input
                      type="range"
                      min="0"
                      max="1"
                      step="0.01"
                      value={settings.advancedSettings.reverbMix.end}
                      onChange={(e) => handleAdvancedChange(
                        'reverbMix',
                        'end',
                        Number(e.target.value)
                      )}
                      className="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer dark:bg-gray-700"
                      aria-label={`Reverb end mix: ${(settings.advancedSettings.reverbMix.end * 100).toFixed(0)}%`}
                    />
                    <span className="ml-2 text-xs min-w-12 text-gray-600 dark:text-gray-300">
                      {(settings.advancedSettings.reverbMix.end * 100).toFixed(0)}%
                    </span>
                  </div>
                </div>
              </div>
            </div>
          )}
          
          {/* Add settings for other effect types as needed */}
        </div>
      )}
    </div>
  );
};

export default BoundaryTransitionSettings;

================
File: client/src/components/EontaCompositionViewer.jsx
================
import React, { useState, useEffect, useCallback, useRef } from 'react';
import { MapPin, Layers, Volume2, Settings, User, Menu, X, Trash2, Download, Share2, Plus, AlertCircle } from 'lucide-react';

// Sample composition data for demonstration
const sampleComposition = {
  title: "Washington Square Park Soundscape",
  description: "An immersive audio experience of Washington Square Park",
  creator: "John Doe",
  isPublic: true,
  location: {
    name: "Washington Square Park, NYC"
  },
  audioRegions: [
    { id: "1", name: "Fountain Area", volume: 80 },
    { id: "2", name: "Eastern Pathways", volume: 65 },
    { id: "3", name: "Western Garden", volume: 72 },
    { id: "4", name: "Northern Plaza", volume: 55 }
  ]
};

const EontaCompositionViewer = () => {
  const [composition, setComposition] = useState(sampleComposition);
  const [isMapVisible, setIsMapVisible] = useState(true);
  const [isMobileMenuOpen, setIsMobileMenuOpen] = useState(false);
  const [activeTab, setActiveTab] = useState('regions');
  const [isDarkMode, setIsDarkMode] = useState(() => {
    // Initialize from localStorage or system preference
    const savedMode = localStorage.getItem('darkMode');
    if (savedMode !== null) {
      return savedMode === 'true';
    }
    return window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
  });
  const [error, setError] = useState(null);
  const [isSaving, setIsSaving] = useState(false);
  const [notification, setNotification] = useState(null);
  const mapRef = useRef(null);

  // Toggle dark mode
  useEffect(() => {
    document.body.classList.toggle('dark', isDarkMode);
    localStorage.setItem('darkMode', isDarkMode);
  }, [isDarkMode]);

  // Format region list items with volume sliders
  const renderRegionList = useCallback(() => {
    if (!composition.audioRegions || !Array.isArray(composition.audioRegions)) {
      return <p>No audio regions available</p>;
    }
    
    return composition.audioRegions.map(region => (
      <div key={region.id} className="mb-4 p-3 bg-white dark:bg-gray-800 rounded-lg shadow">
        <div className="flex justify-between items-center mb-2">
          <h3 className="font-medium text-gray-900 dark:text-white">
            {region.name || `Region ${region.id}`}
          </h3>
          <button 
            className="text-gray-500 hover:text-red-500"
            onClick={() => handleDeleteRegion(region.id)}
            aria-label={`Delete ${region.name || 'region'}`}
          >
            <Trash2 size={18} />
          </button>
        </div>
        
        <div className="flex items-center">
          <Volume2 size={18} className="mr-2 text-gray-500" />
          <input 
            type="range" 
            min="0" 
            max="100" 
            value={region.volume || 0} 
            onChange={(e) => handleVolumeChange(region.id, parseInt(e.target.value, 10))}
            className="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer dark:bg-gray-700"
            aria-label={`Volume for ${region.name || 'region'}`}
          />
          <span className="ml-2 text-sm text-gray-600 dark:text-gray-300 w-8">
            {region.volume || 0}%
          </span>
        </div>
      </div>
    ));
  }, [composition.audioRegions]);

  // Handle volume change for an audio region
  const handleVolumeChange = useCallback((regionId, newVolume) => {
    if (newVolume < 0 || newVolume > 100) {
      console.warn(`Invalid volume value: ${newVolume}`);
      return;
    }
    
    setComposition(prev => ({
      ...prev,
      audioRegions: prev.audioRegions.map(region => 
        region.id === regionId ? { ...region, volume: newVolume } : region
      )
    }));
  }, []);

  // Handle region deletion
  const handleDeleteRegion = useCallback((regionId) => {
    if (!regionId) return;
    
    if (window.confirm("Are you sure you want to delete this region?")) {
      setComposition(prev => ({
        ...prev,
        audioRegions: prev.audioRegions.filter(region => region.id !== regionId)
      }));
    }
  }, []);

  // Add new region
  const handleAddRegion = useCallback(() => {
    const newId = Date.now().toString();
    const newRegion = {
      id: newId,
      name: `New Region ${composition.audioRegions.length + 1}`,
      volume: 75
    };
    
    setComposition(prev => ({
      ...prev,
      audioRegions: [...prev.audioRegions, newRegion]
    }));
  }, [composition.audioRegions]);

  // Toggle mobile menu
  const toggleMobileMenu = useCallback(() => {
    setIsMobileMenuOpen(prev => !prev);
  }, []);
  
  // Handle settings changes
  const handleSettingsChange = useCallback((setting, value) => {
    setComposition(prev => ({
      ...prev,
      settings: {
        ...prev.settings,
        [setting]: value
      }
    }));
  }, []);
  
  // Display a notification that auto-dismisses
  const showNotification = useCallback((message, type = 'info') => {
    setNotification({ message, type });
    setTimeout(() => setNotification(null), 5000);
  }, []);
  
  // Export composition
  const handleExportComposition = useCallback(async () => {
    try {
      setIsSaving(true);
      // In a real implementation, this would call an API
      await new Promise(resolve => setTimeout(resolve, 1000)); // Simulate API call
      
      showNotification('Composition exported successfully!', 'success');
      setIsSaving(false);
    } catch (err) {
      console.error('Export error:', err);
      setError('Failed to export composition. Please try again.');
      setIsSaving(false);
    }
  }, [showNotification]);
  
  // Share composition
  const handleShareComposition = useCallback(() => {
    // In a real implementation, this would generate a sharing link
    navigator.clipboard.writeText(`https://eonta.app/composition/${composition.id || 'demo'}`)
      .then(() => {
        showNotification('Share link copied to clipboard!', 'success');
      })
      .catch(err => {
        console.error('Clipboard error:', err);
        setError('Failed to copy share link. Please try again.');
      });
  }, [composition.id, showNotification]);
  
  return (
    <div className="flex flex-col h-screen bg-gray-100 dark:bg-gray-900 text-gray-800 dark:text-gray-200">
      {/* Header */}
      <header className="bg-white dark:bg-gray-800 shadow-sm px-4 py-3 flex justify-between items-center">
        <div className="flex items-center">
          <h1 className="text-xl font-bold text-blue-600 dark:text-blue-400">EONTA</h1>
          <div className="hidden md:flex ml-6 space-x-1">
            <button 
              onClick={() => setActiveTab('regions')}
              className={`px-3 py-1 rounded-md ${activeTab === 'regions' ? 'bg-blue-100 dark:bg-blue-900 text-blue-600 dark:text-blue-400' : 'text-gray-600 dark:text-gray-300 hover:bg-gray-100 dark:hover:bg-gray-700'}`}
            >
              Regions
            </button>
            <button 
              onClick={() => setActiveTab('settings')}
              className={`px-3 py-1 rounded-md ${activeTab === 'settings' ? 'bg-blue-100 dark:bg-blue-900 text-blue-600 dark:text-blue-400' : 'text-gray-600 dark:text-gray-300 hover:bg-gray-100 dark:hover:bg-gray-700'}`}
            >
              Settings
            </button>
          </div>
        </div>
        
        <div className="flex items-center space-x-2">
          <button 
            onClick={() => setIsDarkMode(!isDarkMode)}
            className="p-2 rounded-full hover:bg-gray-100 dark:hover:bg-gray-700"
            aria-label={isDarkMode ? 'Switch to light mode' : 'Switch to dark mode'}
          >
            {isDarkMode ? 'ðŸŒž' : 'ðŸŒ™'}
          </button>
          
          <button className="p-2 rounded-full hover:bg-gray-100 dark:hover:bg-gray-700" aria-label="User profile">
            <User size={20} className="text-gray-600 dark:text-gray-300" />
          </button>
          
          <button 
            onClick={toggleMobileMenu} 
            className="md:hidden p-2 rounded-full hover:bg-gray-100 dark:hover:bg-gray-700"
            aria-label="Menu"
            aria-expanded={isMobileMenuOpen}
          >
            {isMobileMenuOpen ? <X size={20} /> : <Menu size={20} />}
          </button>
        </div>
      </header>
      
      {/* Mobile Menu */}
      {isMobileMenuOpen && (
        <div className="md:hidden bg-white dark:bg-gray-800 px-4 py-2 shadow-sm">
          <button 
            onClick={() => {setActiveTab('regions'); setIsMobileMenuOpen(false);}}
            className="block w-full text-left py-2 px-3 rounded-md hover:bg-gray-100 dark:hover:bg-gray-700"
          >
            Regions
          </button>
          <button 
            onClick={() => {setActiveTab('settings'); setIsMobileMenuOpen(false);}}
            className="block w-full text-left py-2 px-3 rounded-md hover:bg-gray-100 dark:hover:bg-gray-700"
          >
            Settings
          </button>
        </div>
      )}
      
      {/* Notification */}
      {notification && (
        <div className={`fixed top-4 right-4 z-50 px-4 py-3 rounded-lg shadow-md ${
          notification.type === 'success' ? 'bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200' :
          notification.type === 'error' ? 'bg-red-100 text-red-800 dark:bg-red-900 dark:text-red-200' :
          'bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200'
        }`}>
          {notification.message}
        </div>
      )}
      
      {/* Error message */}
      {error && (
        <div className="bg-red-100 dark:bg-red-900/30 text-red-800 dark:text-red-300 p-3 flex items-start">
          <AlertCircle size={18} className="mr-2 flex-shrink-0 mt-0.5" />
          <div>
            <p>{error}</p>
            <button 
              onClick={() => setError(null)} 
              className="text-sm underline hover:no-underline"
            >
              Dismiss
            </button>
          </div>
        </div>
      )}
      
      {/* Main Content */}
      <div className="flex flex-1 overflow-hidden">
        {/* Map Area */}
        {isMapVisible && (
          <div className="flex-1 bg-gray-300 dark:bg-gray-700 relative" ref={mapRef}>
            <div className="absolute inset-0 flex items-center justify-center">
              <p className="text-gray-600 dark:text-gray-400 text-center">
                Interactive Map Area<br/>
                (Google Maps API Integration)
              </p>
            </div>
            
            {/* Map Controls */}
            <div className="absolute bottom-4 right-4 flex flex-col space-y-2">
              <button 
                className="p-3 bg-white dark:bg-gray-800 rounded-full shadow-md hover:bg-gray-50 dark:hover:bg-gray-700"
                aria-label="Center map"
              >
                <MapPin size={20} className="text-blue-500" />
              </button>
              <button 
                onClick={() => setIsMapVisible(false)}
                className="p-3 bg-white dark:bg-gray-800 rounded-full shadow-md hover:bg-gray-50 dark:hover:bg-gray-700"
                aria-label="Toggle map"
              >
                <Layers size={20} className="text-gray-600 dark:text-gray-300" />
              </button>
            </div>
          </div>
        )}
        
        {/* Side Panel */}
        <div className={`${isMapVisible ? 'w-1/3 min-w-64 border-l' : 'w-full'} bg-white dark:bg-gray-800 border-gray-200 dark:border-gray-700 overflow-y-auto`}>
          <div className="p-4">
            <div className="mb-4">
              <h2 className="text-xl font-bold">{composition.title}</h2>
              <p className="text-sm text-gray-600 dark:text-gray-400">By {composition.creator}</p>
              <p className="mt-2 text-sm">{composition.description}</p>
              
              <div className="flex items-center mt-3 space-x-2">
                <span className="flex items-center text-xs text-gray-500 dark:text-gray-400">
                  <MapPin size={14} className="mr-1" /> {composition.location?.name || 'Unknown location'}
                </span>
                <span className={`px-2 py-0.5 text-xs rounded-full ${composition.isPublic ? 'bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-300' : 'bg-yellow-100 text-yellow-800 dark:bg-yellow-900 dark:text-yellow-300'}`}>
                  {composition.isPublic ? 'Public' : 'Private'}
                </span>
              </div>
            </div>
            
            {/* Tab Navigation */}
            <div className="flex border-b border-gray-200 dark:border-gray-700 mb-4">
              <button 
                onClick={() => setActiveTab('regions')}
                className={`py-2 px-4 font-medium text-sm ${activeTab === 'regions' ? 'border-b-2 border-blue-500 text-blue-600 dark:text-blue-400' : 'text-gray-500 dark:text-gray-400'}`}
              >
                Audio Regions
              </button>
              <button 
                onClick={() => setActiveTab('settings')}
                className={`py-2 px-4 font-medium text-sm ${activeTab === 'settings' ? 'border-b-2 border-blue-500 text-blue-600 dark:text-blue-400' : 'text-gray-500 dark:text-gray-400'}`}
              >
                Settings
              </button>
            </div>
            
            {/* Tab Content */}
            {activeTab === 'regions' && (
              <div>
                <div className="flex justify-between items-center mb-4">
                  <h3 className="font-medium">Audio Regions</h3>
                  <button 
                    className="text-sm px-3 py-1 bg-blue-600 text-white rounded-md hover:bg-blue-700 flex items-center"
                    onClick={handleAddRegion}
                  >
                    <Plus size={16} className="mr-1" /> Add Region
                  </button>
                </div>
                
                {renderRegionList()}
              </div>
            )}
            
            {activeTab === 'settings' && (
              <div>
                <h3 className="font-medium mb-4">Composition Settings</h3>
                
                <div className="space-y-4">
                  <div className="flex items-center justify-between">
                    <span>Master Volume</span>
                    <div className="flex items-center w-32">
                      <input 
                        type="range" 
                        min="0" 
                        max="100" 
                        defaultValue={composition.settings?.masterVolume || 80}
                        onChange={(e) => handleSettingsChange('masterVolume', parseInt(e.target.value, 10))}
                        className="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer dark:bg-gray-700"
                        aria-label="Master volume"
                      />
                      <span className="ml-2 text-sm w-8">{composition.settings?.masterVolume || 80}%</span>
                    </div>
                  </div>
                  
                  <div className="flex items-center justify-between">
                    <span>Audition Mode</span>
                    <label className="relative inline-block w-12 h-6 rounded-full bg-gray-200 dark:bg-gray-700 cursor-pointer">
                      <input 
                        type="checkbox"
                        className="sr-only"
                        checked={composition.settings?.auditionMode || false}
                        onChange={(e) => handleSettingsChange('auditionMode', e.target.checked)}
                        aria-label="Audition mode"
                      />
                      <span className={`absolute left-1 top-1 w-4 h-4 rounded-full bg-white transition-transform ${
                        composition.settings?.auditionMode ? 'transform translate-x-6' : ''
                      }`} />
                    </label>
                  </div>
                  
                  <div className="flex items-center justify-between">
                    <span>Show Transition Zones</span>
                    <label className="relative inline-block w-12 h-6 rounded-full bg-gray-200 dark:bg-gray-700 cursor-pointer">
                      <input 
                        type="checkbox"
                        className="sr-only"
                        checked={composition.settings?.showTransitionZones || false}
                        onChange={(e) => handleSettingsChange('showTransitionZones', e.target.checked)}
                        aria-label="Show transition zones"
                      />
                      <span className={`absolute left-1 top-1 w-4 h-4 rounded-full bg-white transition-transform ${
                        composition.settings?.showTransitionZones ? 'transform translate-x-6' : ''
                      }`} />
                    </label>
                  </div>
                  
                  <div className="pt-4 border-t border-gray-200 dark:border-gray-700">
                    <button 
                      className={`w-full py-2 px-4 bg-blue-100 text-blue-600 dark:bg-blue-900 dark:text-blue-300 rounded-md hover:bg-blue-200 dark:hover:bg-blue-800 flex items-center justify-center ${
                        isSaving ? 'opacity-75 cursor-not-allowed' : ''
                      }`}
                      onClick={handleExportComposition}
                      disabled={isSaving}
                    >
                      <Download size={16} className="mr-2" /> 
                      {isSaving ? 'Exporting...' : 'Export Composition'}
                    </button>
                    
                    <button 
                      className="mt-2 w-full py-2 px-4 bg-gray-100 text-gray-600 dark:bg-gray-700 dark:text-gray-300 rounded-md hover:bg-gray-200 dark:hover:bg-gray-600 flex items-center justify-center"
                      onClick={handleShareComposition}
                    >
                      <Share2 size={16} className="mr-2" /> Share Composition
                    </button>
                  </div>
                </div>
              </div>
            )}
          </div>
        </div>
      </div>
      
      {/* Floating Action Button (mobile) */}
      <div className="md:hidden fixed right-4 bottom-4">
        <button 
          onClick={() => setIsMapVisible(!isMapVisible)}
          className="p-4 bg-blue-600 rounded-full shadow-lg text-white"
          aria-label={isMapVisible ? 'Hide map' : 'Show map'}
        >
          {isMapVisible ? <Layers size={24} /> : <MapPin size={24} />}
        </button>
      </div>
    </div>
  );
};

================
File: client/src/components/PathRecoderUI.jsx
================
import React, { useState, useEffect, useRef, useCallback } from 'react';
import { Play, Square, Map, Timer, Mail, Download, Info, AlertCircle, Activity, Share2 } from 'lucide-react';

/**
 * Path Recorder UI Component
 * Handles recording user paths through audio installations
 */
const PathRecorderUI = ({ pathRecorderService }) => {
  // Component state
  const [isRecording, setIsRecording] = useState(false);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [pointsRecorded, setPointsRecorded] = useState(0);
  const [recordingId, setRecordingId] = useState(null);
  const [processingStatus, setProcessingStatus] = useState(null);
  const [showEmailForm, setShowEmailForm] = useState(false);
  const [email, setEmail] = useState('');
  const [error, setError] = useState(null);
  const [success, setSuccess] = useState(null);
  const [downloadUrl, setDownloadUrl] = useState(null);
  const [compositionData, setCompositionData] = useState(null);
  const [processingProgress, setProcessingProgress] = useState(0);
  
  // Refs for timers
  const timerRef = useRef(null);
  const animationFrameRef = useRef(null);
  const pollingRef = useRef(null);
  
  /**
   * Start recording the user's path
   */
  const startRecording = useCallback(async () => {
    try {
      if (isRecording) {
        console.warn('Recording already in progress');
        return;
      }
      
      setError(null);
      
      // Check if geolocation is available
      if (!navigator.geolocation) {
        setError('Geolocation is not supported by this browser. Please try a different browser.');
        return;
      }
      
      // Check if the pathRecorderService is available
      if (!pathRecorderService) {
        setError('Path recorder service is not available');
        return;
      }
      
      // Get the composition ID from URL or props
      const compositionId = new URLSearchParams(window.location.search).get('compositionId') || 'demo';
      
      // Start recording via service
      const started = await pathRecorderService.startRecording(compositionId);
      
      if (!started) {
        setError('Failed to start recording');
        return;
      }
      
      setIsRecording(true);
      setRecordingDuration(0);
      setPointsRecorded(0);
      
      // Start timer
      const startTime = Date.now();
      
      const updateTimer = () => {
        const elapsed = Date.now() - startTime;
        setRecordingDuration(elapsed);
        animationFrameRef.current = requestAnimationFrame(updateTimer);
      };
      
      animationFrameRef.current = requestAnimationFrame(updateTimer);
      
      // Poll for recording status
      timerRef.current = setInterval(() => {
        const status = pathRecorderService.getStatus();
        if (status && status.isRecording) {
          setPointsRecorded(status.pointsRecorded || 0);
        }
      }, 2000);
      
      // Notify the user that recording has started
      setSuccess('Recording started! Walk through the installation to capture your journey.');
      setTimeout(() => setSuccess(null), 5000);
    } catch (err) {
      console.error('Error starting recording:', err);
      setError(`Failed to start recording: ${err.message || 'Unknown error'}`);
    }
  }, [isRecording, pathRecorderService]);
  
  /**
   * Stop recording the path
   */
  const stopRecording = useCallback(async () => {
    try {
      if (!isRecording) {
        console.warn('No recording in progress');
        return;
      }
      
      // Clear timers
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }
      
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
      
      setIsRecording(false);
      setProcessingStatus('processing');
      setProcessingProgress(0);
      
      // In a real implementation, this would call the path recorder service
      let composition;
      
      if (pathRecorderService) {
        try {
          composition = await pathRecorderService.stopRecording();
          
          if (composition) {
            setRecordingId(composition.recordingId);
            setCompositionData(composition);
            setDownloadUrl(composition.downloadUrl);
          } else {
            setError('No composition was generated. Try recording a longer path.');
            setProcessingStatus(null);
            return;
          }
        } catch (err) {
          console.error('Error stopping recording:', err);
          setError(`Failed to generate composition: ${err.message || 'Unknown error'}`);
          setProcessingStatus(null);
          return;
        }
      } else {
        // Demo mode - simulate response
        const newRecordingId = 'rec_' + Math.random().toString(36).substr(2, 9);
        setRecordingId(newRecordingId);
        
        // Simulate processing completion after a delay
        setTimeout(() => {
          setProcessingStatus('completed');
          setDownloadUrl(`/demo/compositions/${newRecordingId}.mp3`);
        }, 5000);
        
        // Simulate processing progress
        let progress = 0;
        pollingRef.current = setInterval(() => {
          progress += 10;
          setProcessingProgress(Math.min(progress, 100));
          
          if (progress >= 100) {
            clearInterval(pollingRef.current);
            pollingRef.current = null;
          }
        }, 500);
      }
      
      // Show email form to send download link
      setShowEmailForm(true);
    } catch (err) {
      console.error('Error stopping recording:', err);
      setError(`Failed to stop recording: ${err.message || 'Unknown error'}`);
    }
  }, [isRecording, pathRecorderService]);
  
  /**
   * Send download link to email
   */
  const sendDownloadEmail = useCallback(async () => {
    try {
      // Validate email
      if (!email || !/^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(email)) {
        setError('Please enter a valid email address');
        return;
      }
      
      setSuccess('Sending email...');
      
      // In a real implementation, this would call the API
      if (pathRecorderService && recordingId) {
        try {
          const response = await fetch('/api/compositions/send-email', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${localStorage.getItem('authToken')}`
            },
            body: JSON.stringify({
              recordingId,
              email,
              compositionId: compositionData?.compositionId
            })
          });
          
          if (!response.ok) {
            throw new Error(`Server returned ${response.status}: ${response.statusText}`);
          }
          
          setError(null);
          setSuccess(`Download link sent to ${email}! Please check your inbox.`);
          setShowEmailForm(false);
          
          // Clear success message after a delay
          setTimeout(() => setSuccess(null), 5000);
        } catch (err) {
          console.error('Error sending email:', err);
          setError(`Failed to send email: ${err.message || 'Server error'}`);
        }
      } else {
        // Demo mode
        setTimeout(() => {
          setError(null);
          setSuccess(`Download link sent to ${email}! Please check your inbox.`);
          setShowEmailForm(false);
          
          // Clear success message after a delay
          setTimeout(() => setSuccess(null), 5000);
        }, 1000);
      }
    } catch (err) {
      console.error('Error sending email:', err);
      setError(`Failed to send email: ${err.message || 'Unknown error'}`);
    }
  }, [email, recordingId, compositionData, pathRecorderService]);
  
  /**
   * Download the composition directly
   */
  const downloadComposition = useCallback(() => {
    if (!downloadUrl) {
      setError('Download URL is not available');
      return;
    }
    
    // Create a temporary anchor and trigger download
    const a = document.createElement('a');
    a.href = downloadUrl;
    a.download = `eonta-journey-${recordingId || 'recording'}.mp3`;
    a.target = '_blank';
    a.rel = 'noopener noreferrer';
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    
    setSuccess('Download started!');
    setTimeout(() => setSuccess(null), 3000);
  }, [downloadUrl, recordingId]);
  
  /**
   * Format duration as MM:SS
   */
  const formatDuration = useCallback((ms) => {
    const totalSeconds = Math.floor(ms / 1000);
    const minutes = Math.floor(totalSeconds / 60).toString().padStart(2, '0');
    const seconds = (totalSeconds % 60).toString().padStart(2, '0');
    return `${minutes}:${seconds}`;
  }, []);
  
  /**
   * Get recording status text
   */
  const getRecordingStatusText = useCallback(() => {
    if (isRecording) {
      return 'Recording in progress...';
    }
    
    if (processingStatus === 'processing') {
      return 'Processing your recording...';
    }
    
    if (processingStatus === 'completed') {
      return 'Your composition is ready!';
    }
    
    return 'Ready to record';
  }, [isRecording, processingStatus]);
  
  /**
   * Share composition
   */
  const shareComposition = useCallback(() => {
    if (!recordingId) {
      setError('No composition available to share');
      return;
    }
    
    const shareUrl = `${window.location.origin}/share/composition/${recordingId}`;
    
    // Use Web Share API if available
    if (navigator.share) {
      navigator.share({
        title: 'My EONTA Journey',
        text: 'Check out my audio journey through this sound installation!',
        url: shareUrl
      }).catch(err => {
        console.error('Error sharing:', err);
      });
    } else {
      // Fallback to clipboard
      navigator.clipboard.writeText(shareUrl)
        .then(() => {
          setSuccess('Share link copied to clipboard!');
          setTimeout(() => setSuccess(null), 3000);
        })
        .catch(err => {
          console.error('Failed to copy:', err);
          setError('Failed to copy share link. Please try again.');
        });
    }
  }, [recordingId]);
  
  /**
   * Show info/help modal
   */
  const showHelp = useCallback(() => {
    // In a real implementation, this would show a modal
    alert(
      'Path Recorder Help\n\n' +
      '1. Click Start Recording to begin capturing your journey\n' +
      '2. Walk through the installation to experience different audio regions\n' +
      '3. Click Stop when finished to generate your unique composition\n' +
      '4. Enter your email to receive a download link\n\n' +
      'Your composition is a unique souvenir of your journey through the installation!'
    );
  }, []);
  
  // Setup event listeners for path recorder service
  useEffect(() => {
    const handleError = (event) => {
      setError(event.detail.error);
    };
    
    const handleCompletion = (event) => {
      const { recordingData, composition } = event.detail;
      setProcessingStatus('completed');
      setCompositionData(composition);
      setRecordingId(composition.recordingId);
      setDownloadUrl(composition.downloadUrl);
    };
    
    const handlePositionUpdated = (event) => {
      setPointsRecorded(event.detail.pointCount);
    };
    
    // Add event listeners
    window.addEventListener('path-recording-error', handleError);
    window.addEventListener('path-recording-completed', handleCompletion);
    window.addEventListener('path-position-updated', handlePositionUpdated);
    
    // Clean up event listeners
    return () => {
      window.removeEventListener('path-recording-error', handleError);
      window.removeEventListener('path-recording-completed', handleCompletion);
      window.removeEventListener('path-position-updated', handlePositionUpdated);
    };
  }, []);
  
  // Clean up timers on unmount
  useEffect(() => {
    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      
      if (pollingRef.current) {
        clearInterval(pollingRef.current);
      }
    };
  }, []);
  
  return (
    <div className="bg-white dark:bg-gray-800 rounded-lg shadow-md p-4 max-w-md w-full">
      <div className="flex items-center justify-between mb-4">
        <h2 className="text-lg font-bold text-gray-800 dark:text-white flex items-center">
          <Map size={20} className="mr-2 text-blue-500" />
          Path Recorder
        </h2>
        
        <button
          className="p-1 rounded-full hover:bg-gray-100 dark:hover:bg-gray-700 text-gray-600 dark:text-gray-300"
          onClick={showHelp}
          aria-label="Show help"
        >
          <Info size={18} />
        </button>
      </div>
      
      {/* Status */}
      <div className="bg-gray-100 dark:bg-gray-700 rounded-lg p-3 mb-4">
        <p className="text-sm text-gray-700 dark:text-gray-300">
          {getRecordingStatusText()}
        </p>
        
        {isRecording && (
          <div className="mt-2 flex flex-col space-y-2">
            <div className="flex items-center justify-between">
              <span className="text-xs text-gray-500 dark:text-gray-400 flex items-center">
                <Timer size={14} className="mr-1" />
                Duration
              </span>
              <span className="text-sm font-medium text-gray-800 dark:text-white">
                {formatDuration(recordingDuration)}
              </span>
            </div>
            
            <div className="flex items-center justify-between">
              <span className="text-xs text-gray-500 dark:text-gray-400 flex items-center">
                <Map size={14} className="mr-1" />
                GPS Points
              </span>
              <span className="text-sm font-medium text-gray-800 dark:text-white">
                {pointsRecorded}
              </span>
            </div>
          </div>
        )}
        
        {processingStatus === 'processing' && (
          <div className="mt-2">
            <div className="flex items-center justify-between mb-1">
              <span className="text-xs text-gray-500 dark:text-gray-400 flex items-center">
                <Activity size={14} className="mr-1" />
                Processing
              </span>
              <span className="text-xs text-gray-500 dark:text-gray-400">
                {processingProgress}%
              </span>
            </div>
            <div className="w-full bg-gray-200 dark:bg-gray-600 rounded-full h-1.5">
              <div 
                className="bg-blue-500 h-1.5 rounded-full" 
                style={{ width: `${processingProgress}%` }}
              ></div>
            </div>
          </div>
        )}
      </div>
      
      {/* Error Display */}
      {error && (
        <div className="mb-4 bg-red-50 dark:bg-red-900/30 p-3 rounded-lg flex items-start">
          <AlertCircle size={16} className="text-red-500 mt-0.5 mr-2 flex-shrink-0" />
          <div className="text-sm text-red-800 dark:text-red-300">
            {error}
            <button 
              onClick={() => setError(null)} 
              className="block text-xs underline mt-1 hover:no-underline"
            >
              Dismiss
            </button>
          </div>
        </div>
      )}
      
      {/* Success Message */}
      {success && (
        <div className="mb-4 bg-green-50 dark:bg-green-900/30 p-3 rounded-lg">
          <p className="text-sm text-green-800 dark:text-green-300">
            {success}
          </p>
        </div>
      )}
      
      {/* Email Form */}
      {showEmailForm && (
        <div className="mb-4 bg-blue-50 dark:bg-blue-900/30 p-3 rounded-lg">
          <p className="text-sm text-blue-800 dark:text-blue-300 mb-2">
            Enter your email to receive a download link for your composition:
          </p>
          
          <div className="flex items-center">
            <input
              type="email"
              className="flex-1 px-3 py-2 border border-gray-300 dark:border-gray-600 rounded-l-md focus:outline-none focus:ring-2 focus:ring-blue-500 dark:bg-gray-700 dark:text-white text-sm"
              placeholder="your@email.com"
              value={email}
              onChange={(e) => setEmail(e.target.value)}
              aria-label="Email address"
            />
            <button
              className="px-3 py-2 bg-blue-500 text-white rounded-r-md hover:bg-blue-600 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2"
              onClick={sendDownloadEmail}
              aria-label="Send email"
            >
              <Mail size={16} />
            </button>
          </div>
        </div>
      )}
      
      {/* Control Buttons */}
      <div className="flex flex-col space-y-3">
        {!isRecording && processingStatus !== 'processing' && (
          <button
            onClick={startRecording}
            className="w-full py-3 bg-blue-600 text-white rounded-md hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2 flex items-center justify-center"
            disabled={isRecording || processingStatus === 'processing'}
          >
            <Play size={18} className="mr-2" /> Start Recording
          </button>
        )}
        
        {isRecording && (
          <button
            onClick={stopRecording}
            className="w-full py-3 bg-red-600 text-white rounded-md hover:bg-red-700 focus:outline-none focus:ring-2 focus:ring-red-500 focus:ring-offset-2 flex items-center justify-center"
          >
            <Square size={18} className="mr-2" /> Stop Recording
          </button>
        )}
        
        {processingStatus === 'completed' && downloadUrl && (
          <button
            onClick={downloadComposition}
            className="w-full py-3 bg-green-600 text-white rounded-md hover:bg-green-700 focus:outline-none focus:ring-2 focus:ring-green-500 focus:ring-offset-2 flex items-center justify-center"
          >
            <Download size={18} className="mr-2" /> Download Composition
          </button>
        )}
        
        {recordingId && processingStatus === 'completed' && (
          <button
            onClick={shareComposition}
            className="w-full py-3 bg-purple-600 text-white rounded-md hover:bg-purple-700 focus:outline-none focus:ring-2 focus:ring-purple-500 focus:ring-offset-2 flex items-center justify-center"
          >
            <Share2 size={18} className="mr-2" /> Share Journey
          </button>
        )}
      </div>
      
      {/* Composition Details */}
      {compositionData && processingStatus === 'completed' && (
        <div className="mt-4 pt-4 border-t border-gray-200 dark:border-gray-700">
          <h3 className="text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">Journey Summary</h3>
          <div className="bg-gray-50 dark:bg-gray-900 rounded-lg p-3 text-xs">
            <div className="grid grid-cols-2 gap-2">
              <div>
                <span className="text-gray-500 dark:text-gray-400">Duration:</span>
                <p className="font-medium text-gray-800 dark:text-white">
                  {formatDuration(compositionData.duration || recordingDuration)}
                </p>
              </div>
              <div>
                <span className="text-gray-500 dark:text-gray-400">Points:</span>
                <p className="font-medium text-gray-800 dark:text-white">
                  {compositionData.pointCount || pointsRecorded}
                </p>
              </div>
              {compositionData.distance && (
                <div>
                  <span className="text-gray-500 dark:text-gray-400">Distance:</span>
                  <p className="font-medium text-gray-800 dark:text-white">
                    {typeof compositionData.distance === 'number' ? 
                      (compositionData.distance < 1000 ? 
                        `${Math.round(compositionData.distance)}m` : 
                        `${(compositionData.distance / 1000).toFixed(2)}km`) : 
                      compositionData.distance}
                  </p>
                </div>
              )}
              {compositionData.regions && (
                <div>
                  <span className="text-gray-500 dark:text-gray-400">Regions:</span>
                  <p className="font-medium text-gray-800 dark:text-white">
                    {compositionData.regions}
                  </p>
                </div>
              )}
            </div>
          </div>
        </div>
      )}
    </div>
  );
};

/**
 * Component with error boundary
 */
const PathRecorderUIWithErrorBoundary = (props) => {
  const [hasError, setHasError] = useState(false);
  const [errorMessage, setErrorMessage] = useState('');
  
  // Reset error state when props change
  useEffect(() => {
    setHasError(false);
    setErrorMessage('');
  }, [props.pathRecorderService]);
  
  // Handle error
  if (hasError) {
    return (
      <div className="bg-white dark:bg-gray-800 rounded-lg shadow-md p-4 max-w-md w-full">
        <div className="flex items-center mb-4 text-red-500">
          <AlertCircle size={20} className="mr-2" />
          <h2 className="text-lg font-bold">Something went wrong</h2>
        </div>
        <p className="text-gray-700 dark:text-gray-300 mb-4">
          {errorMessage || "The path recorder encountered an error."}
        </p>
        <button
          onClick={() => {
            setHasError(false);
            setErrorMessage('');
          }}
          className="w-full py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700"
        >
          Try Again
        </button>
      </div>
    );
  }
  
  // Try to render component, catch errors
  try {
    return <PathRecorderUI {...props} />;
  } catch (error) {
    console.error('Error rendering PathRecorderUI:', error);
    setHasError(true);
    setErrorMessage(error.message);
    return null;
  }
};

export default PathRecorderUIWithErrorBoundary;

================
File: client/src/services/BoundaryTransitionManager.js
================
/**
 * Enhanced Boundary Transition Manager for EONTA
 * Handles audio transitions between boundaries in the immersive audio environment
 * Maintains the original vision while adding modern security and performance features
 */
class BoundaryTransitionManager {
  constructor(audioService) {
    this.audioService = audioService;
    
    // Available transition types - keeping the original concept from the thesis
    this.transitionTypes = {
      VOLUME_FADE: 'volume_fade',           // Simple volume fade in/out
      LOWPASS_FILTER: 'lowpass_filter',     // Gradually apply lowpass filter (muffling)
      HIGHPASS_FILTER: 'highpass_filter',   // Gradually apply highpass filter (thinning)
      REVERB_TAIL: 'reverb_tail',           // Increase reverb as fading out
      PITCH_SHIFT: 'pitch_shift',           // Slight pitch shift during transition
      DELAY_FEEDBACK: 'delay_feedback',     // Increase delay feedback during transition
      CROSSFADE: 'crossfade',               // Crossfade between regions
      DOPPLER: 'doppler',                   // Doppler effect (pitch shifts as if moving past)
      SPATIAL_BLEND: 'spatial_blend'        // 3D audio panning based on direction
    };
    
    // Default transition settings optimized for listener experience
    this.defaultSettings = {
      fadeInLength: 1.5,         // seconds
      fadeOutLength: 2.0,        // seconds
      fadeInType: this.transitionTypes.VOLUME_FADE,
      fadeOutType: this.transitionTypes.VOLUME_FADE,
      transitionRadius: 10,      // meters - matches the thesis default
      blendingEnabled: true,
      crossfadeOverlap: true,    // enable overlapping transitions between regions
      advancedSettings: {
        // Filter settings - preserving the original audio aesthetic
        lowpassFrequency: {
          start: 20000,           // Hz (fully open)
          end: 500                // Hz (very muffled)
        },
        highpassFrequency: {
          start: 20,              // Hz (fully open)
          end: 2000               // Hz (very thin)
        },
        // Reverb settings
        reverbMix: {
          start: 0.1,             // dry/wet ratio
          end: 0.7                // more wet
        },
        reverbDecay: {
          start: 1.0,             // seconds
          end: 3.0                // seconds
        },
        // Delay settings
        delayFeedback: {
          start: 0.1,             // feedback amount
          end: 0.7                // high feedback
        },
        delayTime: {
          start: 0.25,            // seconds
          end: 0.5                // seconds
        },
        // Pitch settings
        pitchShift: {
          start: 0,               // semitones
          end: -4                 // semitones lower
        },
        // Spatial settings - for the directional audio concept mentioned in thesis
        spatialPosition: {
          x: 0,                   // relative position for 3D audio
          y: 0,
          z: 0
        }
      }
    };
  }
  
  /**
   * Create transition settings for a boundary
   * @param {Object} boundary - The audio boundary object
   * @param {Object} settings - Custom transition settings (optional)
   * @returns {Object} - The complete transition settings
   */
  createTransitionSettings(boundary, settings = {}) {
    if (!boundary) {
      console.warn('Invalid boundary provided');
      return this.defaultSettings;
    }
    
    // Merge custom settings with defaults
    const transitionSettings = {
      ...this.defaultSettings,
      ...settings
    };
    
    // If there are advanced settings, merge them separately to avoid losing nested properties
    if (settings.advancedSettings) {
      transitionSettings.advancedSettings = {
        ...this.defaultSettings.advancedSettings,
        ...settings.advancedSettings
      };
    }
    
    return transitionSettings;
  }
  
  /**
   * Apply transition when entering a boundary
   * Implements the core functionality described in thesis section 3.5.0
   * @param {String} regionId - ID of the region being entered
   * @param {Object} audioData - Audio data including URL
   * @param {Object} transitionSettings - Transition settings for the region
   * @param {Number} distanceToEdge - Distance to the boundary edge in meters
   */
  applyEntryTransition(regionId, audioData, transitionSettings, distanceToEdge = 0) {
    if (!this.audioService) {
      console.error('Audio service not available');
      return;
    }
    
    if (!regionId || !audioData || !audioData.url) {
      console.error('Invalid region data for transition');
      return;
    }
    
    const { fadeInLength, fadeInType, transitionRadius, advancedSettings } = transitionSettings || this.defaultSettings;
    
    // Calculate transition progress based on distance (0 = edge of region, 1 = fully inside)
    // This implements the position-based triggering described in thesis section 3.5.0
    const progress = Math.min(1, Math.max(0, (transitionRadius - distanceToEdge) / transitionRadius));
    
    try {
      // Set up audio node with appropriate transition type
      switch (fadeInType) {
        case this.transitionTypes.VOLUME_FADE:
          // Simple volume fade - fundamental to the EONTA concept
          this.audioService.playAudio(regionId, audioData.url, {
            fadeIn: fadeInLength,
            volume: progress, // Start at current progress level
            loop: true // Matches the looping behavior described in thesis
          });
          break;
          
        case this.transitionTypes.LOWPASS_FILTER:
          // Frequency rises as you enter (opening up)
          const startFreq = advancedSettings.lowpassFrequency.end;
          const endFreq = advancedSettings.lowpassFrequency.start;
          const currentFreq = startFreq + progress * (endFreq - startFreq);
          
          this.audioService.playAudio(regionId, audioData.url, {
            fadeIn: fadeInLength,
            volume: progress,
            loop: true,
            effects: {
              lowpass: true,
              lowpassFrequency: currentFreq
            }
          });
          break;
          
        // Additional transition types preserved from the original design
        // Other cases follow the same pattern as above
        // ...
          
        default:
          // Default to simple volume fade
          this.audioService.playAudio(regionId, audioData.url, {
            fadeIn: fadeInLength,
            volume: progress,
            loop: true
          });
      }
    } catch (error) {
      console.error(`Error applying entry transition for region ${regionId}:`, error);
    }
  }
  
  /**
   * Apply transition when exiting a boundary
   * @param {String} regionId - ID of the region being exited
   * @param {Object} transitionSettings - Transition settings for the region
   * @param {Number} distanceToEdge - Distance to the boundary edge in meters
   */
  applyExitTransition(regionId, transitionSettings, distanceToEdge = 0) {
    if (!this.audioService) {
      console.error('Audio service not available');
      return;
    }
    
    if (!regionId) {
      console.error('Invalid region ID for exit transition');
      return;
    }
    
    const { fadeOutLength, fadeOutType, transitionRadius, advancedSettings } = transitionSettings || this.defaultSettings;
    
    // Calculate transition progress based on distance (1 = edge of region, 0 = beyond transition radius)
    const progress = Math.min(1, Math.max(0, 1 - (distanceToEdge / transitionRadius)));
    
    try {
      // Set up exit transition based on type
      switch (fadeOutType) {
        case this.transitionTypes.VOLUME_FADE:
          // Simple volume fade - implements the core fade functionality
          this.audioService.fadeOutAudio(regionId, fadeOutLength);
          break;
          
        // Additional exit transition types
        // ...
          
        default:
          // Default to simple volume fade
          this.audioService.fadeOutAudio(regionId, fadeOutLength);
      }
    } catch (error) {
      console.error(`Error applying exit transition for region ${regionId}:`, error);
    }
  }
  
  /**
   * Handle crossfade between multiple regions
   * Implements the overlapping regions functionality described in thesis section 3.2.0
   * @param {Array} activeRegions - Currently active audio regions
   * @param {Object} position - Current user position
   */
  handleCrossfades(activeRegions, position) {
    if (!activeRegions || activeRegions.length <= 1 || !position) {
      return;
    }
    
    try {
      // For each pair of active regions, calculate crossfade settings
      for (let i = 0; i < activeRegions.length; i++) {
        for (let j = i + 1; j < activeRegions.length; j++) {
          const region1 = activeRegions[i];
          const region2 = activeRegions[j];
          
          // Skip if either region doesn't have crossfade enabled
          if (!region1.settings?.crossfadeOverlap || !region2.settings?.crossfadeOverlap) {
            continue;
          }
          
          // Calculate distances to both region centers
          const distance1 = this.calculateDistance(position, region1.center);
          const distance2 = this.calculateDistance(position, region2.center);
          
          // Calculate crossfade ratio based on relative distances
          const totalDistance = distance1 + distance2;
          if (totalDistance === 0) continue;
          
          const ratio1 = 1 - (distance1 / totalDistance);
          const ratio2 = 1 - (distance2 / totalDistance);
          
          // Apply volume adjustments for crossfade
          // This creates an inverse relationship - as you move toward one region,
          // its volume increases while the other decreases proportionally
          const baseVolume1 = region1.settings?.volume || 1.0;
          const baseVolume2 = region2.settings?.volume || 1.0;
          
          const crossfadeVolume1 = baseVolume1 * (0.7 + 0.3 * ratio1);
          const crossfadeVolume2 = baseVolume2 * (0.7 + 0.3 * ratio2);
          
          this.audioService.setVolume(region1.id, crossfadeVolume1);
          this.audioService.setVolume(region2.id, crossfadeVolume2);
        }
      }
    } catch (error) {
      console.error('Error handling crossfades:', error);
    }
  }
  
  // Utility method to calculate distance between points
  calculateDistance(point1, point2) {
    if (!point1 || !point2) {
      return Infinity;
    }
    
    try {
      return Math.sqrt(
        Math.pow(point2.lat - point1.lat, 2) + 
        Math.pow(point2.lng - point1.lng, 2)
      );
    } catch (error) {
      console.error('Error calculating distance:', error);
      return Infinity;
    }
  }
}

export default BoundaryTransitionManager;

================
File: client/src/services/PathRecorderService.js
================
import { calculateDistance } from './MapUtils';

/**
 * Path Recorder Service
 * Handles GPS path recording, audio capture, and composition generation
 */
class PathRecorderService {
  constructor(mapService, audioService) {
    this.mapService = mapService;
    this.audioService = audioService;
    this.isRecording = false;
    this.recordedPath = [];
    this.recordedAudio = [];
    this.recordingStartTime = null;
    this.watchId = null;
    this.recordingInterval = null;
    this.currentCompositionId = null;
    this.pathPolyline = null;
    
    // Settings
    this.settings = {
      captureInterval: 1000, // ms between position captures
      minDistance: 2, // minimum distance in meters to record a new point
      maxDuration: 3600000, // maximum recording time (1 hour)
      includeAudioSnapshot: true // whether to include audio snapshots
    };
    
    // Bind methods
    this.startRecording = this.startRecording.bind(this);
    this.stopRecording = this.stopRecording.bind(this);
    this.capturePosition = this.capturePosition.bind(this);
    this.captureAudioState = this.captureAudioState.bind(this);
    this.generateComposition = this.generateComposition.bind(this);
  }
  
  /**
   * Start recording the user's path
   * @param {String} compositionId - ID of the composition being experienced
   * @returns {Boolean} Success flag
   */
  startRecording(compositionId) {
    if (this.isRecording) {
      console.warn('Recording already in progress');
      return false;
    }
    
    // Check if geolocation is available
    if (!navigator.geolocation) {
      console.error('Geolocation is not supported by this browser');
      this._dispatchError('Geolocation is not supported by this browser. Please try a different browser.');
      return false;
    }
    
    // Validate compositionId
    if (!compositionId || typeof compositionId !== 'string') {
      console.error('Invalid composition ID');
      this._dispatchError('Invalid composition ID provided.');
      return false;
    }
    
    this.currentCompositionId = compositionId;
    this.isRecording = true;
    this.recordedPath = [];
    this.recordedAudio = [];
    this.recordingStartTime = Date.now();
    
    // Create initial path point on the map
    if (this.mapService && this.mapService.map && typeof google !== 'undefined' && google.maps) {
      try {
        this.pathPolyline = new google.maps.Polyline({
          path: [],
          geodesic: true,
          strokeColor: '#FF0000',
          strokeOpacity: 1.0,
          strokeWeight: 3,
          map: this.mapService.map
        });
      } catch (error) {
        console.error('Error creating map polyline:', error);
        // Continue without visualization, not a critical error
      }
    }
    
    // Start watching position
    try {
      this.watchId = navigator.geolocation.watchPosition(
        this.capturePosition,
        error => {
          console.error('Error capturing position:', error);
          // Provide user feedback based on error code
          let errorMessage = 'Unknown error occurred while tracking your location.';
          
          if (error.code) {
            switch (error.code) {
              case error.PERMISSION_DENIED:
                errorMessage = 'Location permission denied. Please enable location services to record your path.';
                break;
              case error.POSITION_UNAVAILABLE:
                errorMessage = 'Location information is unavailable. Please try again in an open area.';
                break;
              case error.TIMEOUT:
                errorMessage = 'Location request timed out. Please check your connection and try again.';
                break;
            }
          }
          
          this._dispatchError(errorMessage);
        },
        {
          enableHighAccuracy: true,
          maximumAge: 0,
          timeout: 10000
        }
      );
    } catch (error) {
      console.error('Error starting geolocation watch:', error);
      this._dispatchError('Could not start location tracking. Please check your browser settings.');
      this.isRecording = false;
      return false;
    }
    
    // Set up interval for regular capture
    this.recordingInterval = setInterval(() => {
      // Capture audio state regularly
      if (this.settings.includeAudioSnapshot) {
        this.captureAudioState();
      }
      
      // Check if we've exceeded maximum recording time
      if (Date.now() - this.recordingStartTime > this.settings.maxDuration) {
        this.stopRecording();
        
        // Notify user
        window.dispatchEvent(new CustomEvent('path-recording-max-duration', {
          detail: { 
            message: 'Maximum recording duration reached. Your path has been automatically saved.' 
          }
        }));
      }
    }, this.settings.captureInterval);
    
    // Notify that recording has started
    window.dispatchEvent(new CustomEvent('path-recording-started', {
      detail: {
        timestamp: this.recordingStartTime,
        compositionId: this.currentCompositionId
      }
    }));
    
    return true;
  }
  
  /**
   * Stop recording the path
   * @returns {Promise<Object>} Recording data and composition info
   */
  async stopRecording() {
    if (!this.isRecording) {
      console.warn('No recording in progress');
      return null;
    }
    
    // Clear watch and interval
    if (this.watchId !== null) {
      navigator.geolocation.clearWatch(this.watchId);
      this.watchId = null;
    }
    
    if (this.recordingInterval !== null) {
      clearInterval(this.recordingInterval);
      this.recordingInterval = null;
    }
    
    // Capture final audio state
    if (this.settings.includeAudioSnapshot) {
      this.captureAudioState();
    }
    
    // Set recording flag to false
    this.isRecording = false;
    
    // Generate and process the recorded composition
    const recordingData = {
      compositionId: this.currentCompositionId,
      startTime: this.recordingStartTime,
      endTime: Date.now(),
      duration: Date.now() - this.recordingStartTime,
      path: this.recordedPath,
      audioEvents: this.recordedAudio
    };
    
    // If we have enough points, generate a composition
    if (this.recordedPath.length >= 2) {
      try {
        const composition = await this.generateComposition(recordingData);
        
        // Notify that recording has finished successfully
        window.dispatchEvent(new CustomEvent('path-recording-completed', {
          detail: {
            recordingData,
            composition
          }
        }));
        
        return composition;
      } catch (error) {
        console.error('Error generating composition:', error);
        this._dispatchError('Failed to generate composition from your path.');
        return null;
      }
    } else {
      // Not enough points to generate a meaningful composition
      this._dispatchError('Not enough movement detected to create a composition.');
      return null;
    }
  }
  
  /**
   * Capture the current position
   * @param {Object} position - Geolocation position
   */
  capturePosition(position) {
    if (!this.isRecording) return;
    
    try {
      const newPoint = {
        lat: position.coords.latitude,
        lng: position.coords.longitude,
        accuracy: position.coords.accuracy,
        timestamp: Date.now(),
        timeSinceStart: Date.now() - this.recordingStartTime
      };
      
      // Add altitude if available
      if (position.coords.altitude !== null) {
        newPoint.alt = position.coords.altitude;
      }
      
      // Validate coordinates
      if (!this._isValidCoordinate(newPoint.lat, newPoint.lng)) {
        console.warn('Invalid coordinates received:', newPoint);
        return;
      }
      
      // Only add the point if it's far enough from the last point
      // This prevents cluttering with redundant points
      if (this.recordedPath.length === 0 || 
          calculateDistance(
            this.recordedPath[this.recordedPath.length - 1], 
            newPoint
          ) >= this.settings.minDistance) {
        
        // Add to our data structure
        this.recordedPath.push(newPoint);
        
        // Update the visible path on the map
        if (this.pathPolyline) {
          const pathCoords = this.recordedPath.map(point => ({
            lat: point.lat,
            lng: point.lng
          }));
          
          this.pathPolyline.setPath(pathCoords);
        }
        
        // Capture audio state when position changes significantly
        if (this.settings.includeAudioSnapshot) {
          this.captureAudioState();
        }
        
        // Notify about position update
        window.dispatchEvent(new CustomEvent('path-position-updated', {
          detail: {
            position: newPoint,
            pointCount: this.recordedPath.length
          }
        }));
      }
    } catch (error) {
      console.error('Error processing position data:', error);
    }
  }
  
  /**
   * Validate geographic coordinates
   * @param {Number} lat - Latitude
   * @param {Number} lng - Longitude
   * @returns {Boolean} Whether coordinates are valid
   */
  _isValidCoordinate(lat, lng) {
    return (
      typeof lat === 'number' && 
      typeof lng === 'number' && 
      !isNaN(lat) && 
      !isNaN(lng) && 
      lat >= -90 && 
      lat <= 90 && 
      lng >= -180 && 
      lng <= 180
    );
  }
  
  /**
   * Capture the current audio playback state
   */
  captureAudioState() {
    if (!this.isRecording || !this.audioService) return;
    
    try {
      // Get currently playing audio from the audio service
      const playingAudio = this.audioService.getActiveAudio();
      
      const audioSnapshot = {
        timestamp: Date.now(),
        timeSinceStart: Date.now() - this.recordingStartTime,
        activeRegions: Array.isArray(playingAudio) ? playingAudio.map(audio => ({
          regionId: audio.id,
          volume: audio.volume,
          effects: audio.effects
        })) : []
      };
      
      this.recordedAudio.push(audioSnapshot);
    } catch (error) {
      console.error('Error capturing audio state:', error);
    }
  }
  
  /**
   * Generate a downloadable composition
   * @param {Object} recordingData - Recording data including path and audio events
   * @returns {Promise<Object>} Composition data including download URL
   */
  async generateComposition(recordingData) {
    if (!recordingData || !recordingData.compositionId) {
      throw new Error('Invalid recording data');
    }
    
    try {
      const authToken = localStorage.getItem('authToken');
      
      if (!authToken) {
        throw new Error('Authentication required');
      }
      
      // Submit the recording data to the server to generate the composition
      const response = await fetch('/api/compositions/generate-from-path', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${authToken}`
        },
        body: JSON.stringify({
          compositionId: recordingData.compositionId,
          path: recordingData.path,
          audioEvents: recordingData.audioEvents,
          duration: recordingData.duration,
          startTime: recordingData.startTime,
          endTime: recordingData.endTime,
          userEmail: localStorage.getItem('userEmail') || '' // Optional, for sending email
        })
      });
      
      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Failed to generate composition: ${response.status} ${errorText}`);
      }
      
      return await response.json();
    } catch (error) {
      console.error('Error generating composition:', error);
      throw error;
    }
  }
  
  /**
   * Helper method to dispatch error events
   * @param {String} errorMessage - Error message
   */
  _dispatchError(errorMessage) {
    window.dispatchEvent(new CustomEvent('path-recording-error', {
      detail: { error: errorMessage }
    }));
  }
  
  /**
   * Get recording status
   * @returns {Object} Current recording status
   */
  getStatus() {
    if (!this.isRecording) {
      return {
        isRecording: false
      };
    }
    
    return {
      isRecording: true,
      duration: Date.now() - this.recordingStartTime,
      pointsRecorded: this.recordedPath.length,
      audioSnapshotsRecorded: this.recordedAudio.length,
      compositionId: this.currentCompositionId
    };
  }
  
  /**
   * Clean up resources when component unmounts
   */
  dispose() {
    if (this.isRecording) {
      this.stopRecording();
    }
    
    if (this.pathPolyline) {
      this.pathPolyline.setMap(null);
      this.pathPolyline = null;
    }
  }
}

export default PathRecorderService;

================
File: client/src/services/EnhancedAudioServices.js
================
/**
 * Enhanced Audio Service for EONTA
 * Provides advanced audio playback features with transitions and effects
 * Based on the original EONTA concept with modernized implementation
 */
class EnhancedAudioService {
  constructor() {
    try {
      // Create Web Audio API context as described in thesis section 3.5.0
      this.audioContext = this._createAudioContext();
      this.sources = new Map();
      this.gainNodes = new Map();
      this.effectNodes = new Map();
      this.masterGain = this.audioContext.createGain();
      this.masterGain.connect(this.audioContext.destination);
      
      // Initialize effect factories
      this.effectFactories = {
        lowpass: this.createLowpassFilter.bind(this),
        highpass: this.createHighpassFilter.bind(this),
        reverb: this.createReverb.bind(this),
        delay: this.createDelay.bind(this),
        pitchShift: this.createPitchShifter.bind(this),
        spatialAudio: this.createSpatialAudio.bind(this)
      };
    } catch (error) {
      console.error('Failed to initialize audio context:', error);
    }
  }
  
  /**
   * Create Audio Context with compatibility checks
   * @private
   * @returns {AudioContext} Web Audio API context
   */
  _createAudioContext() {
    // Check if Web Audio API is supported
    if (typeof window === 'undefined' || 
        (!window.AudioContext && !window.webkitAudioContext)) {
      console.error('Web Audio API is not supported in this browser');
      throw new Error('Web Audio API not supported');
    }
    
    const AudioContextClass = window.AudioContext || window.webkitAudioContext;
    const context = new AudioContextClass();
    
    // Handle suspended state (autoplay policy)
    if (context.state === 'suspended') {
      const resumeOnInteraction = () => {
        if (context.state === 'suspended') {
          context.resume().catch(err => {
            console.error('Error resuming audio context:', err);
          });
        }
        
        // Remove listeners after successful resume
        if (context.state === 'running') {
          ['touchend', 'mouseup', 'keydown'].forEach(eventType => {
            document.removeEventListener(eventType, resumeOnInteraction);
          });
        }
      };
      
      ['touchend', 'mouseup', 'keydown'].forEach(eventType => {
        document.addEventListener(eventType, resumeOnInteraction);
      });
    }
    
    return context;
  }
  
  /**
   * Play audio with effects
   * Implements the audio playback described in thesis section 3.5.0
   * @param {String} id - Unique identifier for this audio
   * @param {String} url - URL to audio file
   * @param {Object} options - Playback options
   */
  async playAudio(id, url, options = {}) {
    // Ensure audioContext exists
    if (!this.audioContext) {
      console.error('Audio context not available');
      return false;
    }

    // Default options - matches thesis description
    const defaultOptions = {
      loop: true,  // Essential for continuous playback in boundaries
      volume: 1.0,
      fadeIn: 0.5,
      effects: {}
    };
    
    const settings = { ...defaultOptions, ...options };
    
    try {
      // Validate URL to prevent potential security issues
      const validatedUrl = new URL(url, window.location.origin).toString();
      
      // Fetch audio with timeout
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 30000); // 30 second timeout
      
      const response = await fetch(validatedUrl, { 
        signal: controller.signal 
      });
      clearTimeout(timeoutId);
      
      if (!response.ok) {
        throw new Error(`Failed to fetch audio: ${response.status} ${response.statusText}`);
      }
      
      const arrayBuffer = await response.arrayBuffer();
      const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
      
      // Resume audioContext if it's suspended (handles autoplay policy)
      if (this.audioContext.state === 'suspended') {
        await this.audioContext.resume();
      }
      
      // Create source - fundamental to the EONTA audio system
      const source = this.audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.loop = settings.loop;
      
      // Create gain node for volume control
      const gainNode = this.audioContext.createGain();
      gainNode.gain.value = 0; // Start at 0 for fade-in
      
      // Store references
      this.sources.set(id, source);
      this.gainNodes.set(id, gainNode);
      this.effectNodes.set(id, new Map());
      
      // Connect source to gain
      source.connect(gainNode);
      
      // Create and connect effect chain
      let lastNode = gainNode;
      
      if (settings.effects) {
        for (const [effectType, enabled] of Object.entries(settings.effects)) {
          if (enabled && this.effectFactories[effectType]) {
            const effectNode = this.effectFactories[effectType](settings.effects);
            
            lastNode.connect(effectNode.input);
            lastNode = effectNode.output;
            
            // Store effect nodes
            this.effectNodes.get(id).set(effectType, effectNode);
          }
        }
      }
      
      // Connect to master gain
      lastNode.connect(this.masterGain);
      
      // Start playback
      source.start(0);
      
      // Fade in - implements the smooth transitions described in thesis
      const now = this.audioContext.currentTime;
      gainNode.gain.setValueAtTime(0, now);
      gainNode.gain.linearRampToValueAtTime(settings.volume, now + settings.fadeIn);
      
      return true;
    } catch (error) {
      console.error(`Error playing audio ${id}:`, error);
      return false;
    }
  }
  
  /**
   * Stop audio with fade out
   * @param {String} id - Audio identifier
   * @param {Number} fadeOut - Fade out duration in seconds
   */
  stopAudio(id, fadeOut = 0.5) {
    if (!this.audioContext) return false;
    
    const source = this.sources.get(id);
    const gainNode = this.gainNodes.get(id);
    
    if (!source || !gainNode) return false;
    
    try {
      const now = this.audioContext.currentTime;
      gainNode.gain.setValueAtTime(gainNode.gain.value, now);
      gainNode.gain.linearRampToValueAtTime(0, now + fadeOut);
      
      // Schedule cleanup after fade
      setTimeout(() => {
        try {
          source.stop();
        } catch (e) {
          // Ignore errors if already stopped
        }
        
        this.sources.delete(id);
        this.gainNodes.delete(id);
        
        // Clean up effect nodes
        const effects = this.effectNodes.get(id);
        if (effects) {
          this.effectNodes.delete(id);
        }
      }, fadeOut * 1000);
      
      return true;
    } catch (error) {
      console.error(`Error stopping audio ${id}:`, error);
      return false;
    }
  }
  
  /**
   * Set volume for an audio source
   * @param {String} id - Audio identifier
   * @param {Number} volume - Volume level (0-1)
   */
  setVolume(id, volume) {
    if (!this.audioContext) return false;
    
    const gainNode = this.gainNodes.get(id);
    if (!gainNode) return false;
    
    try {
      // Validate volume is in range 0-1
      const safeVolume = Math.max(0, Math.min(1, volume));
      
      const now = this.audioContext.currentTime;
      gainNode.gain.setValueAtTime(gainNode.gain.value, now);
      gainNode.gain.linearRampToValueAtTime(safeVolume, now + 0.05);
      
      return true;
    } catch (error) {
      console.error(`Error setting volume for ${id}:`, error);
      return false;
    }
  }
  
  /**
   * Fade out audio
   * @param {String} id - Audio identifier
   * @param {Number} duration - Fade duration in seconds
   */
  fadeOutAudio(id, duration = 1.0) {
    if (!this.audioContext) return false;
    
    const gainNode = this.gainNodes.get(id);
    if (!gainNode) return false;
    
    try {
      const now = this.audioContext.currentTime;
      gainNode.gain.setValueAtTime(gainNode.gain.value, now);
      gainNode.gain.linearRampToValueAtTime(0, now + duration);
      
      // Schedule cleanup after fade
      setTimeout(() => {
        if (this.sources.has(id)) {
          this.stopAudio(id, 0);
        }
      }, duration * 1000);
      
      return true;
    } catch (error) {
      console.error(`Error fading out audio ${id}:`, error);
      return false;
    }
  }
  
  /**
   * Apply an effect to an active audio source
   * Implements the audio effects system described in thesis
   * @param {String} id - Audio identifier
   * @param {String} effectType - Type of effect
   * @param {Object} parameters - Effect parameters
   */
  applyEffect(id, effectType, parameters) {
    if (!this.audioContext) return false;
    
    const effectsMap = this.effectNodes.get(id);
    if (!effectsMap) return false;
    
    const effectNode = effectsMap.get(effectType);
    if (!effectNode) return false;
    
    try {
      // Apply parameters to effect node
      switch (effectType) {
        case 'lowpass':
          if (parameters.frequency) {
            effectNode.filter.frequency.setValueAtTime(
              Math.max(20, Math.min(20000, parameters.frequency)),
              this.audioContext.currentTime
            );
          }
          if (parameters.Q) {
            effectNode.filter.Q.setValueAtTime(
              Math.max(0.0001, Math.min(1000, parameters.Q)),
              this.audioContext.currentTime
            );
          }
          break;
          
        // Other effect parameter applications here...
        // Implementation follows similar pattern
          
        default:
          console.warn(`Unknown effect type: ${effectType}`);
          return false;
      }
      
      return true;
    } catch (error) {
      console.error(`Error applying effect ${effectType} to ${id}:`, error);
      return false;
    }
  }
  
  /**
   * Get all currently active audio sources
   * Essential for the audio overlap functionality described in thesis
   * @returns {Array} Array of active audio information
   */
  getActiveAudio() {
    const activeAudio = [];
    
    try {
      this.sources.forEach((source, id) => {
        const gainNode = this.gainNodes.get(id);
        const currentVolume = gainNode ? gainNode.gain.value : 0;
        
        activeAudio.push({
          id,
          volume: currentVolume,
          effects: Array.from(this.effectNodes.get(id) || []).map(([type]) => type)
        });
      });
    } catch (error) {
      console.error('Error getting active audio:', error);
    }
    
    return activeAudio;
  }
  
  /**
   * Set master volume
   * @param {Number} volume - Master volume level (0-1)
   */
  setMasterVolume(volume) {
    if (!this.audioContext) return false;
    
    try {
      // Validate volume
      const safeVolume = Math.max(0, Math.min(1, volume));
      this.masterGain.gain.setValueAtTime(safeVolume, this.audioContext.currentTime);
      return true;
    } catch (error) {
      console.error('Error setting master volume:', error);
      return false;
    }
  }
  
  /**
   * Utility method to suspend/resume audio context
   * Essential for mobile browser compatibility
   */
  async suspendAudio() {
    if (this.audioContext && this.audioContext.state === 'running') {
      try {
        await this.audioContext.suspend();
        return true;
      } catch (error) {
        console.error('Error suspending audio context:', error);
        return false;
      }
    }
    return false;
  }
  
  async resumeAudio() {
    if (this.audioContext && this.audioContext.state === 'suspended') {
      try {
        await this.audioContext.resume();
        return true;
      } catch (error) {
        console.error('Error resuming audio context:', error);
        return false;
      }
    }
    return false;
  }
  
  /**
   * Clean up resources
   * Essential for preventing memory leaks
   */
  dispose() {
    try {
      // Stop all sounds
      for (const id of this.sources.keys()) {
        this.stopAudio(id, 0);
      }
      
      // Close audio context
      if (this.audioContext && this.audioContext.state !== 'closed') {
        this.audioContext.close().catch(err => console.error('Error closing audio context:', err));
      }
      
      // Clear collections
      this.sources.clear();
      this.gainNodes.clear();
      this.effectNodes.clear();
    } catch (error) {
      console.error('Error disposing audio service:', error);
    }
  }
  
  // Effect factory methods here...
  // Implementation follows similar pattern to the original code
}

export default EnhancedAudioService;

================
File: client/src/services/MapUtils.js
================
/**
 * Map Utility Functions for EONTA
 * Contains helper functions for map operations, distance calculations,
 * polygon operations, and coordinate handling
 */

// Constants
const EARTH_RADIUS = 6371000; // Earth's radius in meters
const DEG_TO_RAD = Math.PI / 180;
const RAD_TO_DEG = 180 / Math.PI;
const MAX_POLYGON_POINTS = 1000; // Maximum points in a polygon for safety
const DEFAULT_TOLERANCE = 0.00001; // Default simplification tolerance

/**
 * Validates latitude and longitude values
 * @param {Number} lat - Latitude
 * @param {Number} lng - Longitude
 * @returns {Boolean} True if coordinates are valid
 */
export function isValidCoordinate(lat, lng) {
  return (
    typeof lat === 'number' && 
    typeof lng === 'number' && 
    !isNaN(lat) && 
    !isNaN(lng) && 
    lat >= -90 && 
    lat <= 90 && 
    lng >= -180 && 
    lng <= 180
  );
}

/**
 * Calculate distance between two coordinates in meters
 * @param {Object} point1 - {lat, lng} coordinates
 * @param {Object} point2 - {lat, lng} coordinates
 * @returns {Number} Distance in meters
 */
export function calculateDistance(point1, point2) {
  // Validate inputs
  if (!point1 || !point2) {
    console.warn('Invalid points provided to calculateDistance');
    return 0;
  }
  
  if (!isValidCoordinate(point1.lat, point1.lng) || !isValidCoordinate(point2.lat, point2.lng)) {
    console.warn('Invalid coordinates provided to calculateDistance');
    return 0;
  }
  
  // Use Haversine formula to calculate distance between points
  const dLat = toRad(point2.lat - point1.lat);
  const dLon = toRad(point2.lng - point1.lng);
  
  const a = 
    Math.sin(dLat/2) * Math.sin(dLat/2) +
    Math.cos(toRad(point1.lat)) * Math.cos(toRad(point2.lat)) * 
    Math.sin(dLon/2) * Math.sin(dLon/2);
  
  const c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1-a));
  const distance = EARTH_RADIUS * c;
  
  return distance; // Distance in meters
}

/**
 * Convert degrees to radians
 * @param {Number} degrees - Angle in degrees
 * @returns {Number} Angle in radians
 */
export function toRad(degrees) {
  return degrees * DEG_TO_RAD;
}

/**
 * Convert radians to degrees
 * @param {Number} radians - Angle in radians
 * @returns {Number} Angle in degrees
 */
export function toDeg(radians) {
  return radians * RAD_TO_DEG;
}

/**
 * Calculate distance from point to line segment in meters
 * @param {Number} x - Point x coordinate (longitude)
 * @param {Number} y - Point y coordinate (latitude)
 * @param {Number} x1 - Line segment start x (longitude)
 * @param {Number} y1 - Line segment start y (latitude)
 * @param {Number} x2 - Line segment end x (longitude)
 * @param {Number} y2 - Line segment end y (latitude)
 * @returns {Number} Distance in meters
 */
export function distanceToLine(x, y, x1, y1, x2, y2) {
  // Validate inputs
  if (
    typeof x !== 'number' || 
    typeof y !== 'number' || 
    typeof x1 !== 'number' || 
    typeof y1 !== 'number' || 
    typeof x2 !== 'number' || 
    typeof y2 !== 'number' ||
    isNaN(x) || isNaN(y) || isNaN(x1) || isNaN(y1) || isNaN(x2) || isNaN(y2)
  ) {
    console.warn('Invalid coordinates provided to distanceToLine');
    return Infinity;
  }
  
  const A = x - x1;
  const B = y - y1;
  const C = x2 - x1;
  const D = y2 - y1;
  
  const dot = A * C + B * D;
  const len_sq = C * C + D * D;
  let param = -1;
  
  if (len_sq !== 0) {
    param = dot / len_sq;
  }
  
  let xx, yy;
  
  if (param < 0) {
    xx = x1;
    yy = y1;
  } else if (param > 1) {
    xx = x2;
    yy = y2;
  } else {
    xx = x1 + param * C;
    yy = y1 + param * D;
  }
  
  const dx = x - xx;
  const dy = y - yy;
  
  // Convert to meters using approximate conversion factor
  // 0.00001 in lat/lng ≈ 1.1m at the equator
  const distanceInDegrees = Math.sqrt(dx * dx + dy * dy);
  
  // More accurate conversion based on latitude (coordinates closer to poles are distorted)
  const latFactor = Math.cos(toRad((y1 + y2) / 2)); // Average latitude
  const lngCorrection = latFactor || 0.5; // Avoid division by zero
  
  // Account for different distance scales in latitude vs longitude
  const metersLat = distanceInDegrees * EARTH_RADIUS * DEG_TO_RAD;
  const metersLng = distanceInDegrees * EARTH_RADIUS * DEG_TO_RAD * lngCorrection;
  
  // Simplified approximation
  return (metersLat + metersLng) / 2;
}

/**
 * Calculate the center point of a polygon
 * @param {Array} points - Array of {lat, lng} coordinates
 * @returns {Object|null} Center point as {lat, lng} or null if invalid input
 */
export function calculatePolygonCenter(points) {
  // Validate input
  if (!Array.isArray(points) || points.length === 0) {
    return null;
  }
  
  // Limit the number of points for efficiency and security
  const validPoints = points.slice(0, MAX_POLYGON_POINTS).filter(
    point => isValidCoordinate(point?.lat, point?.lng)
  );
  
  if (validPoints.length === 0) {
    return null;
  }
  
  let sumLat = 0;
  let sumLng = 0;
  
  for (const point of validPoints) {
    sumLat += point.lat;
    sumLng += point.lng;
  }
  
  return {
    lat: sumLat / validPoints.length,
    lng: sumLng / validPoints.length
  };
}

/**
 * Check if a point is inside a polygon
 * @param {Object} point - {lat, lng} coordinates
 * @param {Array} polygon - Array of {lat, lng} coordinates
 * @returns {Boolean} True if point is inside polygon
 */
export function isPointInPolygon(point, polygon) {
  // Validate inputs
  if (!point || !Array.isArray(polygon) || polygon.length < 3) {
    return false;
  }
  
  if (!isValidCoordinate(point.lat, point.lng)) {
    console.warn('Invalid point coordinates provided to isPointInPolygon');
    return false;
  }
  
  // Limit the number of polygon points for security
  const validPolygon = polygon.slice(0, MAX_POLYGON_POINTS).filter(
    p => isValidCoordinate(p?.lat, p?.lng)
  );
  
  if (validPolygon.length < 3) {
    console.warn('Not enough valid points to form a polygon');
    return false;
  }
  
  // Ray casting algorithm
  let inside = false;
  
  for (let i = 0, j = validPolygon.length - 1; i < validPolygon.length; j = i++) {
    const xi = validPolygon[i].lng;
    const yi = validPolygon[i].lat;
    const xj = validPolygon[j].lng;
    const yj = validPolygon[j].lat;
    
    const intersect = ((yi > point.lat) !== (yj > point.lat)) &&
      (point.lng < (xj - xi) * (point.lat - yi) / (yj - yi) + xi);
      
    if (intersect) inside = !inside;
  }
  
  return inside;
}

/**
 * Get distance to polygon edge
 * Negative if inside, positive if outside
 * @param {Object} position - {lat, lng} coordinates
 * @param {Array} polygon - Array of {lat, lng} coordinates
 * @returns {Number} Distance in meters
 */
export function getDistanceToBoundaryEdge(position, polygon) {
  // Validate inputs
  if (!position || !Array.isArray(polygon) || polygon.length < 3) {
    return Infinity;
  }
  
  if (!isValidCoordinate(position.lat, position.lng)) {
    console.warn('Invalid position coordinates provided to getDistanceToBoundaryEdge');
    return Infinity;
  }
  
  // Limit the number of polygon points for security
  const validPolygon = polygon.slice(0, MAX_POLYGON_POINTS).filter(
    p => isValidCoordinate(p?.lat, p?.lng)
  );
  
  if (validPolygon.length < 3) {
    console.warn('Not enough valid points to form a polygon');
    return Infinity;
  }
  
  // Check if point is inside polygon
  const isInside = isPointInPolygon(position, validPolygon);
  
  // Find nearest edge
  let minDistance = Infinity;
  
  for (let i = 0; i < validPolygon.length; i++) {
    const p1 = validPolygon[i];
    const p2 = validPolygon[(i + 1) % validPolygon.length];
    
    const distance = distanceToLine(
      position.lat, position.lng,
      p1.lat, p1.lng,
      p2.lat, p2.lng
    );
    
    minDistance = Math.min(minDistance, distance);
  }
  
  // Return negative if inside, positive if outside
  return isInside ? -minDistance : minDistance;
}

/**
 * Simplify a complex polygon by reducing the number of points
 * while maintaining the general shape
 * @param {Array} points - Array of {lat, lng} coordinates
 * @param {Number} tolerance - Distance tolerance for simplification
 * @returns {Array} Simplified array of coordinates
 */
export function simplifyPolygon(points, tolerance = DEFAULT_TOLERANCE) {
  // Validate inputs
  if (!Array.isArray(points) || points.length < 2) {
    return points || [];
  }
  
  // Ensure tolerance is positive
  const safeTolerance = Math.max(0.000001, tolerance);
  
  // Limit the number of points for security
  const validPoints = points.slice(0, MAX_POLYGON_POINTS).filter(
    p => isValidCoordinate(p?.lat, p?.lng)
  );
  
  if (validPoints.length <= 2) return validPoints;
  
  // Douglas-Peucker algorithm
  const findFurthestPoint = (start, end) => {
    let maxDistance = 0;
    let maxIndex = 0;
    
    for (let i = start + 1; i < end; i++) {
      const distance = distanceToLine(
        validPoints[i].lat, validPoints[i].lng,
        validPoints[start].lat, validPoints[start].lng,
        validPoints[end].lat, validPoints[end].lng
      );
      
      if (distance > maxDistance) {
        maxDistance = distance;
        maxIndex = i;
      }
    }
    
    return { maxDistance, maxIndex };
  };
  
  const simplifySegment = (start, end, result) => {
    const { maxDistance, maxIndex } = findFurthestPoint(start, end);
    
    if (maxDistance > safeTolerance) {
      // Recursively simplify the segments
      simplifySegment(start, maxIndex, result);
      simplifySegment(maxIndex, end, result);
    } else {
      if (!result.includes(validPoints[end])) {
        result.push(validPoints[end]);
      }
    }
  };
  
  const result = [validPoints[0]];
  simplifySegment(0, validPoints.length - 1, result);
  
  return result;
}

/**
 * Expand a polygon outward by a given distance
 * @param {Array} polygon - Array of {lat, lng} coordinates
 * @param {Number} distance - Distance in meters to expand
 * @returns {Array} Expanded polygon
 */
export function expandPolygon(polygon, distance) {
  // Validate inputs
  if (!Array.isArray(polygon) || polygon.length < 3 || typeof distance !== 'number') {
    return polygon || [];
  }
  
  // Ensure distance is within reasonable limits
  const safeDistance = Math.min(10000, Math.max(0, distance)); // Max 10km expansion
  
  // Limit the number of points for security
  const validPolygon = polygon.slice(0, MAX_POLYGON_POINTS).filter(
    p => isValidCoordinate(p?.lat, p?.lng)
  );
  
  if (validPolygon.length < 3) {
    console.warn('Not enough valid points to form a polygon');
    return validPolygon;
  }
  
  // Convert distance to approximate degrees
  // This is a simplified approach - actual implementation would use
  // a more complex algorithm for proper geodesic calculations
  const distanceDegrees = safeDistance / 111000; // 1 degree ≈ 111km at equator
  
  const center = calculatePolygonCenter(validPolygon);
  if (!center) return validPolygon;
  
  return validPolygon.map(point => {
    // Get vector from center to point
    const dx = point.lng - center.lng;
    const dy = point.lat - center.lat;
    
    // Normalize vector
    const length = Math.sqrt(dx * dx + dy * dy);
    if (length === 0) return point; // Avoid division by zero
    
    const nx = dx / length;
    const ny = dy / length;
    
    // Adjust expansion based on latitude (coordinates closer to poles are distorted)
    const latFactor = Math.cos(toRad(point.lat)) || 0.5; // Avoid division by zero
    const lngAdjustment = distanceDegrees / latFactor;
    
    // Return expanded point
    return {
      lat: point.lat + ny * distanceDegrees,
      lng: point.lng + nx * lngAdjustment
    };
  });
}

/**
 * Convert geographic coordinates to web mercator coordinates
 * Useful for flat map projections
 * @param {Number} lat - Latitude in degrees
 * @param {Number} lng - Longitude in degrees
 * @returns {Object} {x, y} coordinates in web mercator
 */
export function geoToMercator(lat, lng) {
  // Validate inputs
  if (!isValidCoordinate(lat, lng)) {
    console.warn('Invalid coordinates provided to geoToMercator');
    return { x: 0, y: 0 };
  }
  
  const x = lng * 20037508.34 / 180;
  let y = Math.log(Math.tan((90 + lat) * Math.PI / 360)) / (Math.PI / 180);
  y = y * 20037508.34 / 180;
  
  return { x, y };
}

/**
 * Convert web mercator coordinates to geographic coordinates
 * @param {Number} x - X coordinate in web mercator
 * @param {Number} y - Y coordinate in web mercator
 * @returns {Object} {lat, lng} geographic coordinates
 */
export function mercatorToGeo(x, y) {
  // Validate inputs
  if (typeof x !== 'number' || typeof y !== 'number' || isNaN(x) || isNaN(y)) {
    console.warn('Invalid coordinates provided to mercatorToGeo');
    return { lat: 0, lng: 0 };
  }
  
  const lng = x * 180 / 20037508.34;
  let lat = y * 180 / 20037508.34;
  lat = 180 / Math.PI * (2 * Math.atan(Math.exp(lat * Math.PI / 180)) - Math.PI / 2);
  
  // Ensure output is within valid range
  lat = Math.max(-90, Math.min(90, lat));
  lng = Math.max(-180, Math.min(180, lng));
  
  return { lat, lng };
}

// Export all functions as a default object
export default {
  isValidCoordinate,
  calculateDistance,
  toRad,
  toDeg,
  distanceToLine,
  calculatePolygonCenter,
  isPointInPolygon,
  getDistanceToBoundaryEdge,
  simplifyPolygon,
  expandPolygon,
  geoToMercator,
  mercatorToGeo
};

================
File: client/src/services/AudioUtils.js
================
/**
 * Audio Utility Functions for EONTA
 * Contains helper functions for audio processing, effects, and conversions
 */

// Constants
const MIN_FREQUENCY = 20; // Minimum audible frequency
const MAX_FREQUENCY = 20000; // Maximum audible frequency
const MAX_BUFFER_SIZE = 10 * 1024 * 1024; // 10MB maximum audio buffer size
const DEFAULT_SAMPLE_RATE = 44100; // Default sample rate if not specified

/**
 * Create a Web Audio API context with error handling
 * @returns {AudioContext|null} Audio context or null if unavailable
 */
export function createAudioContext() {
  try {
    // Check if Web Audio API is supported
    if (typeof window === 'undefined' || 
        (!window.AudioContext && !window.webkitAudioContext)) {
      console.error('Web Audio API is not supported in this browser');
      return null;
    }
    
    const AudioContextClass = window.AudioContext || window.webkitAudioContext;
    const context = new AudioContextClass({
      latencyHint: 'interactive', // Optimize for interactive applications
      sampleRate: DEFAULT_SAMPLE_RATE
    });
    
    // Handle suspended state (autoplay policy)
    if (context.state === 'suspended') {
      const resumeOnInteraction = () => {
        if (context.state === 'suspended') {
          context.resume().catch(err => {
            console.error('Error resuming audio context:', err);
          });
        }
        
        // Remove listeners after successful resume
        if (context.state === 'running') {
          ['touchend', 'mouseup', 'keydown'].forEach(eventType => {
            document.removeEventListener(eventType, resumeOnInteraction);
          });
        }
      };
      
      ['touchend', 'mouseup', 'keydown'].forEach(eventType => {
        document.addEventListener(eventType, resumeOnInteraction);
      });
    }
    
    return context;
  } catch (error) {
    console.error('Error creating audio context:', error);
    return null;
  }
}

/**
 * Load an audio file from URL with security checks
 * @param {AudioContext} audioContext - Web Audio API context
 * @param {String} url - URL to audio file
 * @param {Object} options - Additional options including timeout
 * @returns {Promise<AudioBuffer>} Decoded audio buffer
 */
export async function loadAudioFile(audioContext, url, options = {}) {
  // Parameter validation
  if (!audioContext) {
    throw new Error('Invalid audio context');
  }
  
  if (!url || typeof url !== 'string') {
    throw new Error('Invalid URL provided');
  }
  
  const timeout = options.timeout || 30000; // 30 seconds default timeout
  
  try {
    // Create AbortController for timeout
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);
    
    // Fetch with signal
    const response = await fetch(url, { 
      signal: controller.signal,
      headers: options.headers || {}
    });
    clearTimeout(timeoutId);
    
    if (!response.ok) {
      throw new Error(`Failed to load audio: ${response.status} ${response.statusText}`);
    }
    
    // Check content size
    const contentLength = response.headers.get('content-length');
    if (contentLength && parseInt(contentLength, 10) > MAX_BUFFER_SIZE) {
      throw new Error('Audio file too large');
    }
    
    const arrayBuffer = await response.arrayBuffer();
    
    // Double check buffer size
    if (arrayBuffer.byteLength > MAX_BUFFER_SIZE) {
      throw new Error('Audio buffer exceeds maximum size');
    }
    
    // Resume context if suspended (for mobile browsers)
    if (audioContext.state === 'suspended') {
      await audioContext.resume();
    }
    
    return await audioContext.decodeAudioData(arrayBuffer);
  } catch (error) {
    if (error.name === 'AbortError') {
      throw new Error('Audio loading timed out');
    }
    console.error('Error loading audio file:', error);
    throw error;
  }
}

/**
 * Create a gain node for volume control
 * @param {AudioContext} audioContext - Web Audio API context
 * @param {Number} initialVolume - Initial volume value (0-1)
 * @returns {GainNode} Configured gain node
 */
export function createGainNode(audioContext, initialVolume = 1.0) {
  if (!audioContext) {
    console.error('Invalid audio context provided');
    return null;
  }
  
  try {
    const gainNode = audioContext.createGain();
    
    // Ensure volume is within valid range
    const safeVolume = Math.max(0, Math.min(1, initialVolume));
    gainNode.gain.value = safeVolume;
    
    return gainNode;
  } catch (error) {
    console.error('Error creating gain node:', error);
    return null;
  }
}

/**
 * Validate frequency value to ensure it's within audible range
 * @param {Number} frequency - Frequency value to validate
 * @returns {Number} Validated frequency value
 */
export function validateFrequency(frequency) {
  if (typeof frequency !== 'number' || isNaN(frequency)) {
    return 1000; // Default to 1kHz
  }
  
  return Math.max(MIN_FREQUENCY, Math.min(MAX_FREQUENCY, frequency));
}

/**
 * Create a lowpass filter
 * @param {AudioContext} audioContext - Web Audio API context
 * @param {Number} frequency - Cutoff frequency in Hz
 * @param {Number} Q - Q factor
 * @returns {BiquadFilterNode} Configured filter node
 */
export function createLowpassFilter(audioContext, frequency = 20000, Q = 1.0) {
  if (!audioContext) {
    console.error('Invalid audio context provided');
    return null;
  }
  
  try {
    const filter = audioContext.createBiquadFilter();
    filter.type = 'lowpass';
    filter.frequency.value = validateFrequency(frequency);
    filter.Q.value = Math.max(0.0001, Math.min(1000, Q || 1.0));
    return filter;
  } catch (error) {
    console.error('Error creating lowpass filter:', error);
    return null;
  }
}

/**
 * Create a highpass filter
 * @param {AudioContext} audioContext - Web Audio API context
 * @param {Number} frequency - Cutoff frequency in Hz
 * @param {Number} Q - Q factor
 * @returns {BiquadFilterNode} Configured filter node
 */
export function createHighpassFilter(audioContext, frequency = 20, Q = 1.0) {
  if (!audioContext) {
    console.error('Invalid audio context provided');
    return null;
  }
  
  try {
    const filter = audioContext.createBiquadFilter();
    filter.type = 'highpass';
    filter.frequency.value = validateFrequency(frequency);
    filter.Q.value = Math.max(0.0001, Math.min(1000, Q || 1.0));
    return filter;
  } catch (error) {
    console.error('Error creating highpass filter:', error);
    return null;
  }
}

/**
 * Validate delay time to ensure it's within reasonable range
 * @param {Number} delayTime - Delay time in seconds
 * @returns {Number} Validated delay time
 */
export function validateDelayTime(delayTime) {
  if (typeof delayTime !== 'number' || isNaN(delayTime)) {
    return 0.3; // Default to 300ms
  }
  
  // Limit delay to between 0.01s and 5s
  return Math.max(0.01, Math.min(5, delayTime));
}

/**
 * Create a simple delay effect
 * @param {AudioContext} audioContext - Web Audio API context
 * @param {Number} delayTime - Delay time in seconds
 * @param {Number} feedback - Feedback amount (0-1)
 * @returns {Object} Object containing input, output, and control nodes
 */
export function createDelay(audioContext, delayTime = 0.3, feedback = 0.3) {
  if (!audioContext) {
    console.error('Invalid audio context provided');
    return null;
  }
  
  try {
    const input = audioContext.createGain();
    const output = audioContext.createGain();
    const delay = audioContext.createDelay(5.0); // Maximum 5 seconds delay
    const feedbackGain = audioContext.createGain();
    
    // Ensure parameters are within safe ranges
    delay.delayTime.value = validateDelayTime(delayTime);
    feedbackGain.gain.value = Math.max(0, Math.min(0.95, feedback)); // Limit feedback to avoid infinite loops
    
    input.connect(output); // Direct signal
    input.connect(delay);
    delay.connect(feedbackGain);
    feedbackGain.connect(delay); // Feedback loop
    delay.connect(output);
    
    return {
      input,
      output,
      delay,
      feedback: feedbackGain
    };
  } catch (error) {
    console.error('Error creating delay effect:', error);
    return null;
  }
}

/**
 * Generate a reverb impulse response
 * @param {AudioContext} audioContext - Web Audio API context
 * @param {Number} duration - Duration in seconds
 * @param {Number} decay - Decay rate
 * @returns {AudioBuffer} Impulse response buffer
 */
export function generateReverbImpulse(audioContext, duration = 2.0, decay = 2.0) {
  if (!audioContext) {
    console.error('Invalid audio context provided');
    return null;
  }
  
  try {
    // Ensure parameters are within safe ranges
    const safeDuration = Math.max(0.1, Math.min(5, duration)); // 0.1s to 5s
    const safeDecay = Math.max(0.1, Math.min(10, decay)); // 0.1 to 10
    
    const sampleRate = audioContext.sampleRate;
    const length = Math.floor(sampleRate * safeDuration);
    const impulse = audioContext.createBuffer(2, length, sampleRate);
    
    const leftChannel = impulse.getChannelData(0);
    const rightChannel = impulse.getChannelData(1);
    
    // Fill with white noise with exponential decay
    for (let i = 0; i < length; i++) {
      const amplitude = Math.random() * 2 - 1;
      const decayFactor = Math.exp(-i / (sampleRate * safeDecay / 6));
      
      leftChannel[i] = amplitude * decayFactor;
      rightChannel[i] = amplitude * decayFactor;
    }
    
    return impulse;
  } catch (error) {
    console.error('Error generating reverb impulse:', error);
    return null;
  }
}

/**
 * Create a reverb effect
 * @param {AudioContext} audioContext - Web Audio API context
 * @param {Number} mix - Dry/wet mix (0-1)
 * @param {Number} decayTime - Reverb decay time in seconds
 * @returns {Promise<Object>} Object containing input, output, and control nodes
 */
export async function createReverb(audioContext, mix = 0.3, decayTime = 2.0) {
  if (!audioContext) {
    console.error('Invalid audio context provided');
    return null;
  }
  
  try {
    const input = audioContext.createGain();
    const output = audioContext.createGain();
    const wetGain = audioContext.createGain();
    const dryGain = audioContext.createGain();
    
    // Simple convolver-based reverb
    const convolver = audioContext.createConvolver();
    
    // Ensure parameters are within safe ranges
    const safeMix = Math.max(0, Math.min(1, mix));
    const safeDecayTime = Math.max(0.1, Math.min(5, decayTime));
    
    // Set mix levels
    wetGain.gain.value = safeMix;
    dryGain.gain.value = 1 - safeMix;
    
    // Connect topology
    input.connect(dryGain);
    input.connect(convolver);
    convolver.connect(wetGain);
    dryGain.connect(output);
    wetGain.connect(output);
    
    // Generate impulse response
    const impulseBuffer = await generateReverbImpulse(audioContext, safeDecayTime);
    if (impulseBuffer) {
      convolver.buffer = impulseBuffer;
    }
    
    return {
      input,
      output,
      wetGain,
      dryGain,
      convolver,
      // Add methods for changing parameters
      setMix: (newMix) => {
        const safeNewMix = Math.max(0, Math.min(1, newMix));
        wetGain.gain.value = safeNewMix;
        dryGain.gain.value = 1 - safeNewMix;
      },
      setDecay: async (newDecay) => {
        const newImpulse = await generateReverbImpulse(audioContext, Math.max(0.1, Math.min(5, newDecay)));
        if (newImpulse) {
          convolver.buffer = newImpulse;
        }
      }
    };
  } catch (error) {
    console.error('Error creating reverb effect:', error);
    return null;
  }
}

/**
 * Linear fade between two values over time
 * @param {AudioParam} param - Audio parameter to fade
 * @param {Number} startValue - Starting value
 * @param {Number} endValue - Ending value
 * @param {Number} duration - Duration in seconds
 * @param {AudioContext} audioContext - Web Audio API context
 */
export function linearFade(param, startValue, endValue, duration, audioContext) {
  if (!param || !audioContext) {
    console.error('Invalid parameters for linearFade');
    return;
  }
  
  try {
    const now = audioContext.currentTime;
    const safeDuration = Math.max(0.01, Math.min(60, duration)); // 10ms to 60s
    
    param.setValueAtTime(startValue, now);
    param.linearRampToValueAtTime(endValue, now + safeDuration);
  } catch (error) {
    console.error('Error performing linear fade:', error);
  }
}

/**
 * Exponential fade between two values over time
 * @param {AudioParam} param - Audio parameter to fade
 * @param {Number} startValue - Starting value
 * @param {Number} endValue - Ending value
 * @param {Number} duration - Duration in seconds
 * @param {AudioContext} audioContext - Web Audio API context
 */
export function exponentialFade(param, startValue, endValue, duration, audioContext) {
  if (!param || !audioContext) {
    console.error('Invalid parameters for exponentialFade');
    return;
  }
  
  try {
    const now = audioContext.currentTime;
    const safeDuration = Math.max(0.01, Math.min(60, duration)); // 10ms to 60s
    
    // Avoid zero values for exponential fades
    const safeStart = Math.max(0.0001, startValue);
    const safeEnd = Math.max(0.0001, endValue);
    
    param.setValueAtTime(safeStart, now);
    param.exponentialRampToValueAtTime(safeEnd, now + safeDuration);
  } catch (error) {
    console.error('Error performing exponential fade:', error);
    
    // Fallback to linear fade if exponential fails
    try {
      linearFade(param, startValue, endValue, duration, audioContext);
    } catch (fallbackError) {
      console.error('Fallback linear fade also failed:', fallbackError);
    }
  }
}

/**
 * Connect audio nodes in sequence
 * @param {...AudioNode} nodes - Audio nodes to connect in sequence
 * @returns {Boolean} - Success status
 */
export function connectNodes(...nodes) {
  if (!nodes || nodes.length < 2) {
    console.error('At least two nodes are required for connection');
    return false;
  }
  
  try {
    for (let i = 0; i < nodes.length - 1; i++) {
      if (!nodes[i] || !nodes[i+1]) {
        console.error(`Invalid node at position ${i} or ${i+1}`);
        return false;
      }
      nodes[i].connect(nodes[i + 1]);
    }
    return true;
  } catch (error) {
    console.error('Error connecting audio nodes:', error);
    return false;
  }
}

/**
 * Create a spatial audio panner
 * @param {AudioContext} audioContext - Web Audio API context
 * @param {Number} pan - Initial pan value (-1 to 1)
 * @returns {StereoPannerNode} Configured panner node
 */
export function createStereoPanner(audioContext, pan = 0) {
  if (!audioContext) {
    console.error('Invalid audio context provided');
    return null;
  }
  
  try {
    const panner = audioContext.createStereoPanner();
    
    // Ensure pan value is within valid range
    const safePan = Math.max(-1, Math.min(1, pan));
    panner.pan.value = safePan;
    
    return panner;
  } catch (error) {
    console.error('Error creating stereo panner:', error);
    
    // Fallback for browsers that don't support StereoPannerNode
    try {
      const fallbackPanner = audioContext.createPanner();
      fallbackPanner.panningModel = 'equalpower';
      
      // Convert pan value (-1 to 1) to position
      const x = pan;
      fallbackPanner.setPosition(x, 0, 1 - Math.abs(x));
      
      return fallbackPanner;
    } catch (fallbackError) {
      console.error('Fallback panner creation also failed:', fallbackError);
      return null;
    }
  }
}

/**
 * Convert seconds to time format (MM:SS)
 * @param {Number} seconds - Time in seconds
 * @returns {String} Formatted time string
 */
export function formatTime(seconds) {
  if (typeof seconds !== 'number' || isNaN(seconds) || seconds < 0) {
    return '00:00';
  }
  
  const minutes = Math.floor(seconds / 60);
  const secs = Math.floor(seconds % 60);
  
  return `${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
}

/**
 * Check if the browser supports specific Web Audio API features
 * @returns {Object} Object with feature support flags
 */
export function checkAudioSupport() {
  const support = {
    webAudio: false,
    audioContext: false,
    analyser: false,
    gainNode: false,
    biquadFilter: false,
    convolver: false,
    delay: false,
    dynamicsCompressor: false,
    oscillator: false,
    panner: false,
    stereoPanner: false,
    waveShaper: false
  };
  
  try {
    // Check basic Web Audio support
    support.webAudio = !!(window.AudioContext || window.webkitAudioContext);
    
    if (support.webAudio) {
      const testContext = new (window.AudioContext || window.webkitAudioContext)();
      support.audioContext = true;
      
      // Check for specific node support
      support.analyser = !!testContext.createAnalyser;
      support.gainNode = !!testContext.createGain;
      support.biquadFilter = !!testContext.createBiquadFilter;
      support.convolver = !!testContext.createConvolver;
      support.delay = !!testContext.createDelay;
      support.dynamicsCompressor = !!testContext.createDynamicsCompressor;
      support.oscillator = !!testContext.createOscillator;
      support.panner = !!testContext.createPanner;
      support.stereoPanner = !!testContext.createStereoPanner;
      support.waveShaper = !!testContext.createWaveShaper;
      
      // Close the test context
      testContext.close();
    }
  } catch (error) {
    console.warn('Error checking audio support:', error);
  }
  
  return support;
}

/**
 * Load and decode an audio file from a Blob or File
 * @param {AudioContext} audioContext - Web Audio API context
 * @param {Blob|File} blob - Audio blob or file
 * @returns {Promise<AudioBuffer>} Decoded audio buffer
 */
export async function loadAudioFromBlob(audioContext, blob) {
  if (!audioContext) {
    throw new Error('Invalid audio context');
  }
  
  if (!blob || !(blob instanceof Blob)) {
    throw new Error('Invalid blob provided');
  }
  
  // Check size
  if (blob.size > MAX_BUFFER_SIZE) {
    throw new Error('Audio file too large');
  }
  
  try {
    const arrayBuffer = await blob.arrayBuffer();
    return await audioContext.decodeAudioData(arrayBuffer);
  } catch (error) {
    console.error('Error decoding audio from blob:', error);
    throw error;
  }
}

/**
 * Check if audio playback is allowed (not blocked by browser policies)
 * @param {AudioContext} audioContext - Web Audio API context
 * @returns {Promise<boolean>} Whether audio playback is allowed
 */
export async function checkAudioPlaybackAllowed(audioContext) {
  if (!audioContext) {
    return false;
  }
  
  if (audioContext.state === 'running') {
    return true;
  }
  
  try {
    // Try to resume the audio context
    await audioContext.resume();
    
    // Create a silent oscillator to test playback
    const oscillator = audioContext.createOscillator();
    const gain = audioContext.createGain();
    gain.gain.value = 0; // Silent
    
    oscillator.connect(gain);
    gain.connect(audioContext.destination);
    
    oscillator.start();
    oscillator.stop(audioContext.currentTime + 0.001); // Very short sound
    
    return audioContext.state === 'running';
  } catch (error) {
    console.error('Audio playback check failed:', error);
    return false;
  }
}

// Export all functions as a default object
export default {
  createAudioContext,
  loadAudioFile,
  createGainNode,
  validateFrequency,
  createLowpassFilter,
  createHighpassFilter,
  validateDelayTime,
  createDelay,
  generateReverbImpulse,
  createReverb,
  linearFade,
  exponentialFade,
  connectNodes,
  createStereoPanner,
  formatTime,
  checkAudioSupport,
  loadAudioFromBlob,
  checkAudioPlaybackAllowed
};

================
File: routes/users.js
================
const express = require('express');
const router = express.Router();
const jwt = require('jsonwebtoken');
const bcrypt = require('bcryptjs');
// User model will be created later
// const User = require('../server/models/User');

// Middleware for protected routes
const auth = (req, res, next) => {
  // Get token from header
  const token = req.header('x-auth-token');

  // Check if no token
  if (!token) {
    return res.status(401).json({ message: 'No token, authorization denied' });
  }

  try {
    // Verify token
    const decoded = jwt.verify(token, process.env.JWT_SECRET);
    
    // Add user from payload
    req.user = decoded.user;
    next();
  } catch (err) {
    res.status(401).json({ message: 'Token is not valid' });
  }
};

// @route   POST api/users/register
// @desc    Register a user
// @access  Public
router.post('/register', async (req, res) => {
  try {
    const { name, email, password } = req.body;

    // Simple validation
    if (!name || !email || !password) {
      return res.status(400).json({ message: 'Please enter all fields' });
    }

    // For now, just return success 
    // In the full implementation, you would:
    // 1. Check if user already exists
    // 2. Create new user with hashed password
    // 3. Save to database
    // 4. Generate JWT token
    
    res.status(200).json({ 
      success: true,
      message: 'Registration endpoint reached successfully'
    });
    
  } catch (err) {
    console.error(err);
    res.status(500).json({ message: 'Server error' });
  }
});

// @route   POST api/users/login
// @desc    Login user
// @access  Public
router.post('/login', async (req, res) => {
  try {
    const { email, password } = req.body;

    // Simple validation
    if (!email || !password) {
      return res.status(400).json({ message: 'Please enter all fields' });
    }

    // For now, just return success with dummy token
    // In the full implementation, you would:
    // 1. Find user by email
    // 2. Validate password
    // 3. Generate JWT token
    
    const token = jwt.sign(
      { user: { id: 'dummy-user-id' } },
      process.env.JWT_SECRET || 'temporary_secret_key',
      { expiresIn: process.env.JWT_EXPIRATION || '7d' }
    );

    res.status(200).json({
      success: true,
      token,
      message: 'Login endpoint reached successfully'
    });
    
  } catch (err) {
    console.error(err);
    res.status(500).json({ message: 'Server error' });
  }
});

// @route   GET api/users/profile
// @desc    Get user profile
// @access  Private
router.get('/profile', auth, async (req, res) => {
  try {
    // For now, just return success with dummy user data
    // In the full implementation, you would find the user by ID
    
    res.status(200).json({
      success: true,
      user: {
        id: req.user.id,
        name: 'Test User',
        email: 'test@example.com'
      },
      message: 'Profile endpoint reached successfully'
    });
    
  } catch (err) {
    console.error(err);
    res.status(500).json({ message: 'Server error' });
  }
});

module.exports = router;

================
File: routes/audio.js
================
const express = require('express');
const router = express.Router();
const multer = require('multer');
const AWS = require('aws-sdk');
const path = require('path');
const jwt = require('jsonwebtoken');
const AudioConverter = require('../server/services/AudioConverter');
const audioConfig = require('../server/config/audio');

// Configure AWS S3
AWS.config.update({
  accessKeyId: process.env.AWS_ACCESS_KEY_ID,
  secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
  region: process.env.AWS_REGION
});

const s3 = new AWS.S3();

// Configure Multer for file upload
const storage = multer.memoryStorage();
const upload = multer({
  storage,
  limits: {
    fileSize: process.env.MAX_AUDIO_FILE_SIZE_MB * 1024 * 1024 || audioConfig.maxFileSizeMB * 1024 * 1024,
  },
  fileFilter: (req, file, cb) => {
    // Accept all audio files
    if (file.mimetype.startsWith('audio/')) {
      cb(null, true);
    } else {
      cb(new Error('Invalid file type. Only audio files are allowed.'), false);
    }
  }
});

// Middleware for protected routes
const auth = (req, res, next) => {
  const token = req.header('x-auth-token');
  if (!token) return res.status(401).json({ message: 'No token, authorization denied' });
  
  try {
    const decoded = jwt.verify(token, process.env.JWT_SECRET);
    req.user = decoded.user;
    next();
  } catch (err) {
    res.status(401).json({ message: 'Token is not valid' });
  }
};

// @route   POST api/audio/upload
// @desc    Upload audio file to S3 with automatic conversion to optimal format
// @access  Private
router.post('/upload', auth, upload.single('audio'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ message: 'No file uploaded' });
    }

    let fileBuffer = req.file.buffer;
    let fileName = req.file.originalname;
    let fileMimetype = req.file.mimetype;
    let wasConverted = false;

    // Check if conversion is needed
    if (AudioConverter.isConversionNeeded(req.file.mimetype)) {
      try {
        console.log(`Converting file from ${req.file.mimetype} to MP3 format...`);
        const convertedFile = await AudioConverter.convertToOptimizedFormat(
          req.file.buffer, 
          req.file.originalname,
          req.file.mimetype
        );
        
        fileBuffer = convertedFile.buffer;
        fileName = convertedFile.filename;
        fileMimetype = convertedFile.mimetype;
        wasConverted = true;
        
        console.log(`Conversion complete. New file size: ${fileBuffer.length / 1024} KB`);
      } catch (conversionError) {
        console.error('Error converting audio file:', conversionError);
        // Fall back to original file if conversion fails
        console.log('Using original file instead');
      }
    }

    // Create unique filename with timestamp
    const uniqueFileName = `${Date.now()}-${path.basename(fileName)}`;
    
    // Set up S3 upload parameters
    const params = {
      Bucket: process.env.S3_BUCKET_NAME,
      Key: uniqueFileName,
      Body: fileBuffer,
      ContentType: fileMimetype,
      ACL: 'private', // Restrict public access
      CacheControl: `max-age=${audioConfig.caching.maxAge}` // Cache based on config
    };

    // Upload to S3
    const uploadResult = await s3.upload(params).promise();
    
    res.status(200).json({
      success: true,
      file: {
        name: uniqueFileName,
        originalName: fileName,
        url: uploadResult.Location,
        size: fileBuffer.length,
        type: fileMimetype,
        converted: wasConverted
      },
      message: `File upload successful${wasConverted ? ' (converted to MP3)' : ''}`
    });
  } catch (err) {
    console.error('Error in audio upload:', err);
    res.status(500).json({ message: 'Server error', error: err.message });
  }
});

// @route   GET api/audio/:fileName
// @desc    Get a signed URL to access an audio file
// @access  Private
router.get('/:fileName', auth, async (req, res) => {
  try {
    const { fileName } = req.params;
    
    // Set up S3 params for generating a signed URL
    const params = {
      Bucket: process.env.S3_BUCKET_NAME,
      Key: fileName,
      Expires: 3600 // URL expiration time in seconds (1 hour)
    };

    // Generate a signed URL for the file
    const signedUrl = await s3.getSignedUrlPromise('getObject', params);
    
    res.status(200).json({
      success: true,
      url: signedUrl,
      expires: new Date(Date.now() + 3600 * 1000).toISOString()
    });
  } catch (err) {
    console.error('Error generating signed URL:', err);
    res.status(500).json({ message: 'Server error', error: err.message });
  }
});

module.exports = router;

================
File: routes/compositions.js
================
const express = require('express');
const router = express.Router();
const jwt = require('jsonwebtoken');
// Composition model will be created later
// const Composition = require('../server/models/Composition');

// Middleware for protected routes
const auth = (req, res, next) => {
  const token = req.header('x-auth-token');
  if (!token) return res.status(401).json({ message: 'No token, authorization denied' });
  
  try {
    const decoded = jwt.verify(token, process.env.JWT_SECRET || 'temporary_secret_key');
    req.user = decoded.user;
    next();
  } catch (err) {
    res.status(401).json({ message: 'Token is not valid' });
  }
};

// @route   GET api/compositions
// @desc    Get all compositions (or filtered by query params)
// @access  Public
router.get('/', async (req, res) => {
  try {
    // For now, just return success with dummy data
    res.status(200).json({
      success: true,
      compositions: [
        {
          id: '1',
          title: 'Sample Composition 1',
          creator: 'User 1',
          location: 'New York',
          createdAt: new Date()
        },
        {
          id: '2',
          title: 'Sample Composition 2',
          creator: 'User 2',
          location: 'San Francisco',
          createdAt: new Date()
        }
      ],
      message: 'Compositions endpoint reached successfully'
    });
  } catch (err) {
    console.error(err);
    res.status(500).json({ message: 'Server error' });
  }
});

// @route   POST api/compositions
// @desc    Create a new composition
// @access  Private
router.post('/', auth, async (req, res) => {
  try {
    const { title, description, boundaries, paths } = req.body;

    // Simple validation
    if (!title) {
      return res.status(400).json({ message: 'Title is required' });
    }

    // For now, just return success
    // In the full implementation, you would:
    // 1. Create a new composition with user as creator
    // 2. Save to database
    
    res.status(201).json({
      success: true,
      composition: {
        id: 'new-composition-id',
        title,
        description,
        creator: req.user.id,
        boundaries,
        paths,
        createdAt: new Date()
      },
      message: 'Composition created successfully'
    });
  } catch (err) {
    console.error(err);
    res.status(500).json({ message: 'Server error' });
  }
});

// @route   GET api/compositions/:id
// @desc    Get a composition by ID
// @access  Public
router.get('/:id', async (req, res) => {
  try {
    const { id } = req.params;

    // For now, just return success with dummy data
    res.status(200).json({
      success: true,
      composition: {
        id,
        title: 'Sample Composition',
        description: 'This is a sample composition',
        creator: 'User 1',
        location: 'New York',
        boundaries: [
          { lat: 40.712776, lng: -74.005974 },
          { lat: 40.712976, lng: -74.005674 },
          { lat: 40.713176, lng: -74.006274 }
        ],
        paths: [
          {
            points: [
              { lat: 40.712876, lng: -74.005874, timestamp: new Date() },
              { lat: 40.712976, lng: -74.005774, timestamp: new Date() }
            ],
            audioUrl: 'https://eonta-audio-files.s3.amazonaws.com/sample.mp3'
          }
        ],
        createdAt: new Date()
      },
      message: 'Composition retrieved successfully'
    });
  } catch (err) {
    console.error(err);
    res.status(500).json({ message: 'Server error' });
  }
});

// @route   PUT api/compositions/:id
// @desc    Update a composition
// @access  Private
router.put('/:id', auth, async (req, res) => {
  try {
    const { id } = req.params;
    const { title, description, boundaries, paths } = req.body;

    // For now, just return success
    res.status(200).json({
      success: true,
      composition: {
        id,
        title,
        description,
        boundaries,
        paths,
        updatedAt: new Date()
      },
      message: 'Composition updated successfully'
    });
  } catch (err) {
    console.error(err);
    res.status(500).json({ message: 'Server error' });
  }
});

// @route   DELETE api/compositions/:id
// @desc    Delete a composition
// @access  Private
router.delete('/:id', auth, async (req, res) => {
  try {
    const { id } = req.params;

    // For now, just return success
    res.status(200).json({
      success: true,
      message: 'Composition deleted successfully'
    });
  } catch (err) {
    console.error(err);
    res.status(500).json({ message: 'Server error' });
  }
});

// @route   POST api/compositions/:id/share
// @desc    Share a composition via email
// @access  Private
router.post('/:id/share', auth, async (req, res) => {
  try {
    const { id } = req.params;
    const { recipientEmail } = req.body;

    // Simple validation
    if (!recipientEmail) {
      return res.status(400).json({ message: 'Recipient email is required' });
    }

    // For now, just return success
    // In the full implementation, you would:
    // 1. Verify the composition exists
    // 2. Send an email using your email service
    
    res.status(200).json({
      success: true,
      message: 'Composition shared successfully (email functionality will be implemented later)'
    });
  } catch (err) {
    console.error(err);
    res.status(500).json({ message: 'Server error' });
  }
});

module.exports = router;
